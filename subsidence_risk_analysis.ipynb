{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "# Subsidence Risk Analysis for Bristol\n",
    "\n",
    "This notebook performs geospatial analysis to assess **subsidence risk for individual buildings** based on:\n",
    "\n",
    "- **üå≥ Tree Data** - From Bristol City Council API (crown width, species, location)\n",
    "- **üè† Building Data** - From OpenStreetMap via Overpass API  \n",
    "- **üåç Soil Data** - From British Geological Survey (BGS) WMS service\n",
    "\n",
    "## How It Works\n",
    "\n",
    "The analysis calculates a **risk score (0-10) for each building** by combining:\n",
    "\n",
    "1. **Soil Risk (40%)** - Samples BGS soil texture raster at building location\n",
    "   - Heavy clay soils = highest risk (shrink-swell potential)\n",
    "   - Sandy soils = lowest risk (stable)\n",
    "   - Unknown/no-data areas = score of 0 (excluded from risk)\n",
    "\n",
    "2. **Tree Proximity Risk (60%)** - Weighted distance calculation\n",
    "   - Trees within root spread zone = high influence  \n",
    "   - Root spread estimated as 1.5√ó crown width\n",
    "   - Species-specific risk factors (willow > oak > birch)\n",
    "   - Very close trees (< 5m) get bonus scoring\n",
    "\n",
    "## Outputs\n",
    "\n",
    "- `bristol_buildings_scored.geojson` - All buildings with risk scores and attributes\n",
    "- `subsidence_risk_buildings.html` - Interactive map with toggleable layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports\n",
    "\n",
    "Import required libraries for geospatial analysis, visualization, and API calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import folium\n",
    "from folium import plugins\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import requests\n",
    "import osmnx as ox\n",
    "from shapely.geometry import Point, Polygon, box\n",
    "from IPython.display import display, IFrame\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Set plotting style with fallback\n",
    "try:\n",
    "    plt.style.use('seaborn-v0_8-darkgrid')\n",
    "except:\n",
    "    try:\n",
    "        plt.style.use('seaborn-darkgrid')\n",
    "    except:\n",
    "        plt.style.use('default')\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## 2. Study Area Configuration\n",
    "\n",
    "Define the Bristol study area bounds. Three preset areas are available:\n",
    "- **TINY** (~0.25 km¬≤) - Quick testing\n",
    "- **TEST** (~4 km¬≤) - Development  \n",
    "- **FULL** (~180 km¬≤) - Full Bristol analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bristol city center coordinates\n",
    "BRISTOL_CENTER = (51.4545, -2.5879)\n",
    "\n",
    "# FULL STUDY AREA (use this for final analysis)\n",
    "BRISTOL_BOUNDS_FULL = {\n",
    "    'north': 51.5200,\n",
    "    'south': 51.4000,\n",
    "    'east': -2.5000,\n",
    "    'west': -2.7000\n",
    "}\n",
    "\n",
    "# SMALL TEST AREA (use this for testing - ~2km x 2km around city center)\n",
    "BRISTOL_BOUNDS_TEST = {\n",
    "    'north': 51.4645,  # ~1km north of center\n",
    "    'south': 51.4445,  # ~1km south of center\n",
    "    'east': -2.5779,   # ~1km east of center\n",
    "    'west': -2.5979    # ~1km west of center\n",
    "}\n",
    "\n",
    "# TINY TEST AREA (for quick testing - ~500m x 500m) - RECOMMENDED FOR FIRST RUN\n",
    "BRISTOL_BOUNDS_TINY = {\n",
    "    'north': 51.4595,  # ~500m north of center\n",
    "    'south': 51.4495,  # ~500m south of center\n",
    "    'east': -2.5829,   # ~500m east of center\n",
    "    'west': -2.5929    # ~500m west of center\n",
    "}\n",
    "\n",
    "# Switch between test areas (BRISTOL_BOUNDS_TINY is fastest for testing)\n",
    "BRISTOL_BOUNDS = BRISTOL_BOUNDS_FULL\n",
    "\n",
    "# Create bounding box geometry\n",
    "bbox_geometry = box(\n",
    "    BRISTOL_BOUNDS['west'],\n",
    "    BRISTOL_BOUNDS['south'],\n",
    "    BRISTOL_BOUNDS['east'],\n",
    "    BRISTOL_BOUNDS['north']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c122b06",
   "metadata": {},
   "source": [
    "## 3. Risk Scoring Configuration\n",
    "\n",
    "All scoring parameters are defined in a single location for easy adjustment.\n",
    "\n",
    "### How Risk is Calculated\n",
    "\n",
    "Each building receives a **combined risk score (0-10)** calculated as:\n",
    "\n",
    "```\n",
    "Combined Score = (Soil Score √ó 0.4) + (Tree Score √ó 0.6)\n",
    "```\n",
    "\n",
    "#### Soil Score (40% weight)\n",
    "Based on soil type at building location. Clay soils shrink when dry and swell when wet, causing ground movement.\n",
    "\n",
    "| Soil Type | Score | Why |\n",
    "|-----------|-------|-----|\n",
    "| Heavy Clay | 10 | Extreme shrink-swell |\n",
    "| Clay | 8 | High shrink-swell |\n",
    "| Clay Loam | 6 | Moderate shrink-swell |\n",
    "| Loam | 4 | Some movement |\n",
    "| Sandy Loam | 2 | Minimal movement |\n",
    "| Sand | 1 | Stable |\n",
    "| Unknown | 0 | No data - excluded |\n",
    "\n",
    "#### Tree Score (60% weight)\n",
    "Based on proximity to trees. Tree roots extract water from soil, causing clay shrinkage.\n",
    "\n",
    "**Scoring approach:**\n",
    "- Trees within root zone (1.5√ó crown width): **3-5 points** per tree\n",
    "- Very close trees (< 5m): **+2 point bonus**\n",
    "- Trees outside root zone: Linear decay to 0 at 30m\n",
    "\n",
    "**Species Risk Factors:**\n",
    "- üå≥ Willow: 1.8√ó (very high water uptake)\n",
    "- üå≥ Poplar: 1.7√ó\n",
    "- üå≥ Oak: 1.5√ó\n",
    "- üå≥ Ash: 1.3√ó\n",
    "- üå≥ Default: 1.0√ó\n",
    "\n",
    "### Worked Examples\n",
    "\n",
    "**Example 1: High Risk Building**\n",
    "- Soil: Heavy Clay (score = 10)\n",
    "- Trees: 2 willows within 5m (tree score = 9.0)\n",
    "- **Combined: (10 √ó 0.4) + (9.0 √ó 0.6) = 4.0 + 5.4 = 9.4** ‚ö†Ô∏è HIGH\n",
    "\n",
    "**Example 2: Low Risk Building**\n",
    "- Soil: Sandy Loam (score = 2)\n",
    "- Trees: 1 birch at 20m (tree score = 0.5)\n",
    "- **Combined: (2 √ó 0.4) + (0.5 √ó 0.6) = 0.8 + 0.3 = 1.1** ‚úÖ LOW\n",
    "\n",
    "**Example 3: Tree-Dominated Risk**\n",
    "- Soil: Loam (score = 4)  \n",
    "- Trees: 3 oaks within root zone (tree score = 8.0)\n",
    "- **Combined: (4 √ó 0.4) + (8.0 √ó 0.6) = 1.6 + 4.8 = 6.4** üü° MEDIUM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "7e7b90d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "RISK SCORING CONFIGURATION\n",
      "============================================================\n",
      "\n",
      "üìä Risk Weights:\n",
      "   Soil:  40%\n",
      "   Trees: 60%\n",
      "\n",
      "üåç Soil Risk Scores:\n",
      "   Heavy Clay  : 10.0 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   Clay        :  8.0 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   Clay Loam   :  6.0 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   Loam        :  4.0 ‚ñà‚ñà‚ñà‚ñà\n",
      "   Sandy Loam  :  2.0 ‚ñà‚ñà\n",
      "   Sand        :  1.0 ‚ñà\n",
      "\n",
      "üå≥ Tree Configuration:\n",
      "   Max influence distance: 30.0m\n",
      "   Root spread: 1.5√ó crown width\n",
      "\n",
      "üå≥ Species Risk Factors (top 5):\n",
      "   willow    : 1.8√ó\n",
      "   poplar    : 1.7√ó\n",
      "   oak       : 1.5√ó\n",
      "   ash       : 1.3√ó\n",
      "   sycamore  : 1.2√ó\n",
      "\n",
      "‚ö†Ô∏è Risk Categories:\n",
      "   HIGH:   score ‚â• 7.0\n",
      "   MEDIUM: score ‚â• 4.0\n",
      "   LOW:    score < 4.0\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# RISK SCORING CONFIGURATION\n",
    "# ============================================\n",
    "# All scoring parameters in one place for easy adjustment\n",
    "\n",
    "# ----- RISK WEIGHTING -----\n",
    "# How much each factor contributes to final score\n",
    "RISK_WEIGHTS = {\n",
    "    'soil': 0.4,    # 40% - Soil type is primary driver\n",
    "    'tree': 0.6     # 60% - Tree proximity is secondary\n",
    "}\n",
    "\n",
    "# ----- SOIL RISK SCORES -----\n",
    "# Score based on shrink-swell potential (0-10 scale)\n",
    "SOIL_RISK_SCORES = {\n",
    "    'Heavy Clay': 10.0,   # Highest risk - extreme shrink-swell\n",
    "    'Clay': 8.0,          # High risk\n",
    "    'Clay Loam': 6.0,     # Moderate-high risk\n",
    "    'Loam': 4.0,          # Moderate risk\n",
    "    'Sandy Loam': 2.0,    # Low risk\n",
    "    'Sand': 1.0,          # Minimal risk - stable\n",
    "    'Unknown': 0.0        # No BGS data - doesn't contribute to score\n",
    "}\n",
    "\n",
    "# Soil raster code to score mapping (from SoilRasterHandler classification)\n",
    "# Unknown (0) gets score of 0 so buildings without BGS data don't get inflated scores\n",
    "SOIL_CODE_SCORES = {\n",
    "    6: 10.0,  # Heavy Clay\n",
    "    5: 8.0,   # Clay\n",
    "    4: 6.0,   # Clay Loam\n",
    "    3: 4.0,   # Loam\n",
    "    2: 2.0,   # Sandy Loam\n",
    "    1: 1.0,   # Sand\n",
    "    0: 0.0    # Unknown - no soil data, no contribution to score\n",
    "}\n",
    "\n",
    "# ----- TREE RISK CONFIGURATION -----\n",
    "TREE_CONFIG = {\n",
    "    'max_influence_distance_m': 30.0,    # Trees beyond this don't contribute\n",
    "    'root_spread_multiplier': 1.5,       # Root spread = crown_width √ó this (typical rule of thumb)\n",
    "    'default_crown_width_m': 8.0,        # Default if data missing\n",
    "    'distance_decay_power': 1.0,         # Linear decay (was 2.0 - too aggressive)\n",
    "    'max_trees_to_consider': 50,         # Performance limit\n",
    "    'base_tree_score': 3.0,              # Score for single tree within root zone\n",
    "    'close_tree_bonus': 2.0,             # Extra score for trees < 5m away\n",
    "    'score_cap': 10.0,                   # Maximum tree score\n",
    "}\n",
    "\n",
    "# Species risk factors - some trees extract more water\n",
    "# Values > 1.0 increase risk, < 1.0 decrease risk\n",
    "SPECIES_RISK_FACTORS = {\n",
    "    'willow': 1.8,       # Very high water uptake\n",
    "    'poplar': 1.7,       # High water uptake\n",
    "    'oak': 1.5,          # Moderate-high\n",
    "    'ash': 1.3,          # Moderate\n",
    "    'sycamore': 1.2,\n",
    "    'lime': 1.1,\n",
    "    'cherry': 1.0,\n",
    "    'birch': 0.9,        # Lower water uptake\n",
    "    'pine': 0.7,         # Evergreen, lower risk\n",
    "    'default': 1.0       # Unknown species\n",
    "}\n",
    "\n",
    "# ----- RISK CATEGORIES -----\n",
    "# Score thresholds for categorization\n",
    "RISK_THRESHOLDS = {\n",
    "    'high': 7.0,      # Score >= 7 is HIGH risk\n",
    "    'medium': 4.0,    # Score >= 4 is MEDIUM risk\n",
    "    # Below 4 is LOW risk\n",
    "}\n",
    "\n",
    "# Print configuration summary\n",
    "print(\"=\" * 60)\n",
    "print(\"RISK SCORING CONFIGURATION\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nüìä Risk Weights:\")\n",
    "print(f\"   Soil:  {RISK_WEIGHTS['soil']*100:.0f}%\")\n",
    "print(f\"   Trees: {RISK_WEIGHTS['tree']*100:.0f}%\")\n",
    "\n",
    "print(f\"\\nüåç Soil Risk Scores:\")\n",
    "for soil, score in SOIL_RISK_SCORES.items():\n",
    "    if soil != 'Unknown':\n",
    "        bar = '‚ñà' * int(score)\n",
    "        print(f\"   {soil:12s}: {score:4.1f} {bar}\")\n",
    "\n",
    "print(f\"\\nüå≥ Tree Configuration:\")\n",
    "print(f\"   Max influence distance: {TREE_CONFIG['max_influence_distance_m']}m\")\n",
    "print(f\"   Root spread: {TREE_CONFIG['root_spread_multiplier']}√ó crown width\")\n",
    "\n",
    "print(f\"\\nüå≥ Species Risk Factors (top 5):\")\n",
    "sorted_species = sorted(SPECIES_RISK_FACTORS.items(), key=lambda x: x[1], reverse=True)\n",
    "for species, factor in sorted_species[:5]:\n",
    "    print(f\"   {species:10s}: {factor:.1f}√ó\")\n",
    "\n",
    "print(f\"\\n‚ö†Ô∏è Risk Categories:\")\n",
    "print(f\"   HIGH:   score ‚â• {RISK_THRESHOLDS['high']}\")\n",
    "print(f\"   MEDIUM: score ‚â• {RISK_THRESHOLDS['medium']}\")\n",
    "print(f\"   LOW:    score < {RISK_THRESHOLDS['medium']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## 4. Data Collection\n",
    "\n",
    "### 4.1 Tree Data (Bristol City Council API)\n",
    "\n",
    "Fetches the complete tree inventory from Bristol City Council's open data API:\n",
    "- Location (point geometry in WGS84)\n",
    "- Crown width, height, and area measurements\n",
    "- Species information (common and Latin names)\n",
    "- Diameter at breast height (DBH)\n",
    "\n",
    "**Source:** Bristol City Council GIS MapServer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching tree data from Bristol City Council API...\n",
      "Total records available: 55359\n",
      "Fetching records 0 to 1000...\n",
      "Total records available: 55359\n",
      "Fetching records 0 to 1000...\n",
      "Fetching records 1000 to 2000...\n",
      "Fetching records 1000 to 2000...\n",
      "Fetching records 2000 to 3000...\n",
      "Fetching records 2000 to 3000...\n",
      "Fetching records 3000 to 4000...\n",
      "Fetching records 3000 to 4000...\n",
      "Fetching records 4000 to 5000...\n",
      "Fetching records 4000 to 5000...\n",
      "Fetching records 5000 to 6000...\n",
      "Fetching records 5000 to 6000...\n",
      "Fetching records 6000 to 7000...\n",
      "Fetching records 6000 to 7000...\n",
      "Fetching records 7000 to 8000...\n",
      "Fetching records 7000 to 8000...\n",
      "Fetching records 8000 to 9000...\n",
      "Fetching records 8000 to 9000...\n",
      "Fetching records 9000 to 10000...\n",
      "Fetching records 9000 to 10000...\n",
      "Fetching records 10000 to 11000...\n",
      "Fetching records 10000 to 11000...\n",
      "Fetching records 11000 to 12000...\n",
      "Fetching records 11000 to 12000...\n",
      "Fetching records 12000 to 13000...\n",
      "Fetching records 12000 to 13000...\n",
      "Fetching records 13000 to 14000...\n",
      "Fetching records 13000 to 14000...\n",
      "Fetching records 14000 to 15000...\n",
      "Fetching records 14000 to 15000...\n",
      "Fetching records 15000 to 16000...\n",
      "Fetching records 15000 to 16000...\n",
      "Fetching records 16000 to 17000...\n",
      "Fetching records 16000 to 17000...\n",
      "Fetching records 17000 to 18000...\n",
      "Fetching records 17000 to 18000...\n",
      "Fetching records 18000 to 19000...\n",
      "Fetching records 18000 to 19000...\n",
      "Fetching records 19000 to 20000...\n",
      "Fetching records 19000 to 20000...\n",
      "Fetching records 20000 to 21000...\n",
      "Fetching records 20000 to 21000...\n",
      "Fetching records 21000 to 22000...\n",
      "Fetching records 21000 to 22000...\n",
      "Fetching records 22000 to 23000...\n",
      "Fetching records 22000 to 23000...\n",
      "Fetching records 23000 to 24000...\n",
      "Fetching records 23000 to 24000...\n",
      "Fetching records 24000 to 25000...\n",
      "Fetching records 24000 to 25000...\n",
      "Fetching records 25000 to 26000...\n",
      "Fetching records 25000 to 26000...\n",
      "Fetching records 26000 to 27000...\n",
      "Fetching records 26000 to 27000...\n",
      "Fetching records 27000 to 28000...\n",
      "Fetching records 27000 to 28000...\n",
      "Fetching records 28000 to 29000...\n",
      "Fetching records 28000 to 29000...\n",
      "Fetching records 29000 to 30000...\n",
      "Fetching records 29000 to 30000...\n",
      "Fetching records 30000 to 31000...\n",
      "Fetching records 30000 to 31000...\n",
      "Fetching records 31000 to 32000...\n",
      "Fetching records 31000 to 32000...\n",
      "Fetching records 32000 to 33000...\n",
      "Fetching records 32000 to 33000...\n",
      "Fetching records 33000 to 34000...\n",
      "Fetching records 33000 to 34000...\n",
      "Fetching records 34000 to 35000...\n",
      "Fetching records 34000 to 35000...\n",
      "Fetching records 35000 to 36000...\n",
      "Fetching records 35000 to 36000...\n",
      "Fetching records 36000 to 37000...\n",
      "Fetching records 36000 to 37000...\n",
      "Fetching records 37000 to 38000...\n",
      "Fetching records 37000 to 38000...\n",
      "Fetching records 38000 to 39000...\n",
      "Fetching records 38000 to 39000...\n",
      "Fetching records 39000 to 40000...\n",
      "Fetching records 39000 to 40000...\n",
      "Fetching records 40000 to 41000...\n",
      "Fetching records 40000 to 41000...\n",
      "Fetching records 41000 to 42000...\n",
      "Fetching records 41000 to 42000...\n",
      "Fetching records 42000 to 43000...\n",
      "Fetching records 42000 to 43000...\n",
      "Fetching records 43000 to 44000...\n",
      "Fetching records 43000 to 44000...\n",
      "Fetching records 44000 to 45000...\n",
      "Fetching records 44000 to 45000...\n",
      "Fetching records 45000 to 46000...\n",
      "Fetching records 45000 to 46000...\n",
      "Fetching records 46000 to 47000...\n",
      "Fetching records 46000 to 47000...\n",
      "Fetching records 47000 to 48000...\n",
      "Fetching records 47000 to 48000...\n",
      "Fetching records 48000 to 49000...\n",
      "Fetching records 48000 to 49000...\n",
      "Fetching records 49000 to 50000...\n",
      "Fetching records 49000 to 50000...\n",
      "Fetching records 50000 to 51000...\n",
      "Fetching records 50000 to 51000...\n",
      "Fetching records 51000 to 52000...\n",
      "Fetching records 51000 to 52000...\n",
      "Fetching records 52000 to 53000...\n",
      "Fetching records 52000 to 53000...\n",
      "Fetching records 53000 to 54000...\n",
      "Fetching records 53000 to 54000...\n",
      "Fetching records 54000 to 55000...\n",
      "Fetching records 54000 to 55000...\n",
      "Fetching records 55000 to 55359...\n",
      "Fetching records 55000 to 55359...\n",
      "Successfully fetched 55359 total features\n",
      "Successfully fetched 55359 total features\n",
      "Collected 55235 tree features within study area\n",
      "Available columns: ['geometry', 'OBJECTID', 'ASSET_ID', 'SITE_NAME', 'PLOT_NO', 'FEATURE_ID', 'LOCATION', 'TYPE', 'PRIM_MEAS', 'UNIT', 'SITE_CODE', 'FEAT_GP', 'X', 'Y', 'DEAD', 'CLASSIFICATION', 'EXTENT_EASTING_1', 'EXTENT_NORTHING_1', 'EXTENT_EASTING_2', 'EXTENT_NORTHING_2', 'LAYERS', 'LATIN_CODE', 'LATIN_NAME', 'FEATURE_TYPE_NAME', 'COMMON_NAME', 'FULL_COMMON_NAME', 'CROWN_HEIGHT', 'CROWN_WIDTH', 'CROWN_AREA', 'DBH', 'LOCATION_RISK_ZONE', 'EPICORMIC', 'INSURANCE_CLAIM_HISTORY', 'CENTRAL_ASSET_ID', 'CONTRACT_AREA_NAME', 'CUSTOMER', 'DEAD_FLAG', 'FEATURE_GROUP', 'FEATURE_GROUP_CODE', 'FEATURETYPECODE', 'NOTES', 'REVISION_NO', 'TREE_SPECIES', 'TREE_MODIFIED_RISK', 'CANOPY_SIZE_AT_MATURITY', 'SPONSORSHIP', 'SPONSORSHIP_PACKAGE', 'PLANTING_SEASON', 'PLANTING_FUNDER', 'PLANTING_NOTES', 'SPECIES_NOTES', 'TREE_TYPE', 'JOBS_REQUIRED', 'SERVICES_VISIBILITY', 'CONSTRAINTS', 'CANCELLATION_REASON', 'NOTES_FOR_STATUS', 'CANCELLATION_NOTES', 'created_user', 'created_date', 'last_edited_user', 'last_edited_date']\n",
      "\n",
      "Tree data shape: (55235, 62)\n",
      "Tree data columns: ['geometry', 'OBJECTID', 'ASSET_ID', 'SITE_NAME', 'PLOT_NO', 'FEATURE_ID', 'LOCATION', 'TYPE', 'PRIM_MEAS', 'UNIT', 'SITE_CODE', 'FEAT_GP', 'X', 'Y', 'DEAD', 'CLASSIFICATION', 'EXTENT_EASTING_1', 'EXTENT_NORTHING_1', 'EXTENT_EASTING_2', 'EXTENT_NORTHING_2', 'LAYERS', 'LATIN_CODE', 'LATIN_NAME', 'FEATURE_TYPE_NAME', 'COMMON_NAME', 'FULL_COMMON_NAME', 'CROWN_HEIGHT', 'CROWN_WIDTH', 'CROWN_AREA', 'DBH', 'LOCATION_RISK_ZONE', 'EPICORMIC', 'INSURANCE_CLAIM_HISTORY', 'CENTRAL_ASSET_ID', 'CONTRACT_AREA_NAME', 'CUSTOMER', 'DEAD_FLAG', 'FEATURE_GROUP', 'FEATURE_GROUP_CODE', 'FEATURETYPECODE', 'NOTES', 'REVISION_NO', 'TREE_SPECIES', 'TREE_MODIFIED_RISK', 'CANOPY_SIZE_AT_MATURITY', 'SPONSORSHIP', 'SPONSORSHIP_PACKAGE', 'PLANTING_SEASON', 'PLANTING_FUNDER', 'PLANTING_NOTES', 'SPECIES_NOTES', 'TREE_TYPE', 'JOBS_REQUIRED', 'SERVICES_VISIBILITY', 'CONSTRAINTS', 'CANCELLATION_REASON', 'NOTES_FOR_STATUS', 'CANCELLATION_NOTES', 'created_user', 'created_date', 'last_edited_user', 'last_edited_date']\n",
      "\n",
      "Sample tree data:\n",
      "                    geometry  OBJECTID    ASSET_ID  \\\n",
      "0  POINT (-2.57807 51.48386)  20951518    00818916   \n",
      "1   POINT (-2.5784 51.48419)  20951519    00821743   \n",
      "2  POINT (-2.56105 51.47476)  20951520  PK00116904   \n",
      "3  POINT (-2.56024 51.47497)  20951521  PK00116901   \n",
      "4  POINT (-2.56031 51.47475)  20951522  PK00116902   \n",
      "\n",
      "                                 SITE_NAME   PLOT_NO FEATURE_ID LOCATION  \\\n",
      "0  Dovercourt Road To Muller Road Footpath  200001.0     FRAEXE     None   \n",
      "1  Dovercourt Road To Muller Road Footpath  200002.0                None   \n",
      "2      Eastville Roundabout M32 Junction 2  200005.0                None   \n",
      "3      Eastville Roundabout M32 Junction 2  200002.0                None   \n",
      "4      Eastville Roundabout M32 Junction 2  200003.0                None   \n",
      "\n",
      "                             TYPE  PRIM_MEAS    UNIT SITE_CODE FEAT_GP  \\\n",
      "0  PK: Tree - Parks and Green Spa          1  Number   4513696      TR   \n",
      "1  PK: Tree - Parks and Green Spa          3  Number   4513696      TR   \n",
      "2     PK: Tree - Highways Adopted          1  Number   4513795      TR   \n",
      "3     PK: Tree - Highways Adopted          1  Number   4513795      TR   \n",
      "4     PK: Tree - Highways Adopted          1  Number   4513795      TR   \n",
      "\n",
      "           X          Y DEAD CLASSIFICATION  EXTENT_EASTING_1  \\\n",
      "0  359956.40  176260.01    N             01         359956.40   \n",
      "1  359933.76  176296.56    N           RY04         359933.76   \n",
      "2  361130.01  175238.29    N           RY03         361130.01   \n",
      "3  361186.30  175261.56    N           RY04         361186.30   \n",
      "4  361181.52  175236.67    N           RY04         361181.52   \n",
      "\n",
      "   EXTENT_NORTHING_1  EXTENT_EASTING_2  EXTENT_NORTHING_2  LAYERS LATIN_CODE  \\\n",
      "0          176260.01         359956.40          176260.01  FRAEXE       FREX   \n",
      "1          176296.56         359933.76          176296.56               PRZZ   \n",
      "2          175238.29         361130.01          175238.29               MEGL   \n",
      "3          175261.56         361186.30          175261.56               MEGL   \n",
      "4          175236.67         361181.52          175236.67               MEGL   \n",
      "\n",
      "                     LATIN_NAME FEATURE_TYPE_NAME   COMMON_NAME  \\\n",
      "0            Fraxinus excelsior              None           Ash   \n",
      "1      Prunus - Species Unknown              None        Cherry   \n",
      "2  Metasequoia glyptostroboides              None  Dawn Redwood   \n",
      "3  Metasequoia glyptostroboides              None  Dawn Redwood   \n",
      "4  Metasequoia glyptostroboides              None  Dawn Redwood   \n",
      "\n",
      "      FULL_COMMON_NAME       CROWN_HEIGHT        CROWN_WIDTH  \\\n",
      "0           Common ash          15 Metres          14 Metres   \n",
      "1  Unidentified cherry  No Code Allocated  No Code Allocated   \n",
      "2         Dawn redwood           6 Metres           4 Metres   \n",
      "3         Dawn redwood           4 Metres           1 Metres   \n",
      "4         Dawn redwood           4 Metres           1 Metres   \n",
      "\n",
      "            CROWN_AREA                DBH LOCATION_RISK_ZONE EPICORMIC  \\\n",
      "0                       No Code Allocated    Risk Zone D (5)             \n",
      "1                       No Code Allocated    Risk Zone D (5)             \n",
      "2  20.1 - 100 M2 (New)     10 Centimetres    Risk Zone A (2)             \n",
      "3    Up to 20 M2 (New)      7 Centimetres    Risk Zone B (3)             \n",
      "4    Up to 20 M2 (New)      6 Centimetres    Risk Zone B (3)             \n",
      "\n",
      "  INSURANCE_CLAIM_HISTORY CENTRAL_ASSET_ID CONTRACT_AREA_NAME CUSTOMER  \\\n",
      "0       No Code Allocated         00818916               None     None   \n",
      "1       No Code Allocated         00821743               None     None   \n",
      "2       No Code Allocated       PK00116904               None     None   \n",
      "3       No Code Allocated       PK00116901               None     None   \n",
      "4       No Code Allocated       PK00116902               None     None   \n",
      "\n",
      "  DEAD_FLAG FEATURE_GROUP FEATURE_GROUP_CODE FEATURETYPECODE NOTES  \\\n",
      "0         N          None                 TR            None  None   \n",
      "1         N          None                 TR            None  None   \n",
      "2         N          None                 TR            None  None   \n",
      "3         N          None                 TR            None  None   \n",
      "4         N          None                 TR            None  None   \n",
      "\n",
      "  REVISION_NO                  TREE_SPECIES TREE_MODIFIED_RISK  \\\n",
      "0        None            Fraxinus excelsior    Risk Zone D (5)   \n",
      "1        None      Prunus - Species Unknown    Risk Zone D (5)   \n",
      "2        None  Metasequoia glyptostroboides    Risk Zone A (2)   \n",
      "3        None  Metasequoia glyptostroboides    Risk Zone B (3)   \n",
      "4        None  Metasequoia glyptostroboides    Risk Zone B (3)   \n",
      "\n",
      "  CANOPY_SIZE_AT_MATURITY SPONSORSHIP SPONSORSHIP_PACKAGE PLANTING_SEASON  \\\n",
      "0                    None        None                None            None   \n",
      "1                    None        None                None            None   \n",
      "2                    None        None                None            None   \n",
      "3                    None        None                None            None   \n",
      "4                    None        None                None            None   \n",
      "\n",
      "  PLANTING_FUNDER PLANTING_NOTES SPECIES_NOTES TREE_TYPE JOBS_REQUIRED  \\\n",
      "0            None           None          None      None          None   \n",
      "1            None           None          None      None          None   \n",
      "2            None           None          None      None          None   \n",
      "3            None           None          None      None          None   \n",
      "4            None           None          None      None          None   \n",
      "\n",
      "  SERVICES_VISIBILITY CONSTRAINTS CANCELLATION_REASON NOTES_FOR_STATUS  \\\n",
      "0                None        None                None             None   \n",
      "1                None        None                None             None   \n",
      "2                None        None                None             None   \n",
      "3                None        None                None             None   \n",
      "4                None        None                None             None   \n",
      "\n",
      "  CANCELLATION_NOTES created_user   created_date last_edited_user  \\\n",
      "0               None   PARKS_EDIT  1764306015000       PARKS_EDIT   \n",
      "1               None   PARKS_EDIT  1764306015000       PARKS_EDIT   \n",
      "2               None   PARKS_EDIT  1764306015000       PARKS_EDIT   \n",
      "3               None   PARKS_EDIT  1764306015000       PARKS_EDIT   \n",
      "4               None   PARKS_EDIT  1764306015000       PARKS_EDIT   \n",
      "\n",
      "   last_edited_date  \n",
      "0     1764306015000  \n",
      "1     1764306015000  \n",
      "2     1764306015000  \n",
      "3     1764306015000  \n",
      "4     1764306015000  \n",
      "\n",
      "Geometry types: ['Point']\n",
      "Collected 55235 tree features within study area\n",
      "Available columns: ['geometry', 'OBJECTID', 'ASSET_ID', 'SITE_NAME', 'PLOT_NO', 'FEATURE_ID', 'LOCATION', 'TYPE', 'PRIM_MEAS', 'UNIT', 'SITE_CODE', 'FEAT_GP', 'X', 'Y', 'DEAD', 'CLASSIFICATION', 'EXTENT_EASTING_1', 'EXTENT_NORTHING_1', 'EXTENT_EASTING_2', 'EXTENT_NORTHING_2', 'LAYERS', 'LATIN_CODE', 'LATIN_NAME', 'FEATURE_TYPE_NAME', 'COMMON_NAME', 'FULL_COMMON_NAME', 'CROWN_HEIGHT', 'CROWN_WIDTH', 'CROWN_AREA', 'DBH', 'LOCATION_RISK_ZONE', 'EPICORMIC', 'INSURANCE_CLAIM_HISTORY', 'CENTRAL_ASSET_ID', 'CONTRACT_AREA_NAME', 'CUSTOMER', 'DEAD_FLAG', 'FEATURE_GROUP', 'FEATURE_GROUP_CODE', 'FEATURETYPECODE', 'NOTES', 'REVISION_NO', 'TREE_SPECIES', 'TREE_MODIFIED_RISK', 'CANOPY_SIZE_AT_MATURITY', 'SPONSORSHIP', 'SPONSORSHIP_PACKAGE', 'PLANTING_SEASON', 'PLANTING_FUNDER', 'PLANTING_NOTES', 'SPECIES_NOTES', 'TREE_TYPE', 'JOBS_REQUIRED', 'SERVICES_VISIBILITY', 'CONSTRAINTS', 'CANCELLATION_REASON', 'NOTES_FOR_STATUS', 'CANCELLATION_NOTES', 'created_user', 'created_date', 'last_edited_user', 'last_edited_date']\n",
      "\n",
      "Tree data shape: (55235, 62)\n",
      "Tree data columns: ['geometry', 'OBJECTID', 'ASSET_ID', 'SITE_NAME', 'PLOT_NO', 'FEATURE_ID', 'LOCATION', 'TYPE', 'PRIM_MEAS', 'UNIT', 'SITE_CODE', 'FEAT_GP', 'X', 'Y', 'DEAD', 'CLASSIFICATION', 'EXTENT_EASTING_1', 'EXTENT_NORTHING_1', 'EXTENT_EASTING_2', 'EXTENT_NORTHING_2', 'LAYERS', 'LATIN_CODE', 'LATIN_NAME', 'FEATURE_TYPE_NAME', 'COMMON_NAME', 'FULL_COMMON_NAME', 'CROWN_HEIGHT', 'CROWN_WIDTH', 'CROWN_AREA', 'DBH', 'LOCATION_RISK_ZONE', 'EPICORMIC', 'INSURANCE_CLAIM_HISTORY', 'CENTRAL_ASSET_ID', 'CONTRACT_AREA_NAME', 'CUSTOMER', 'DEAD_FLAG', 'FEATURE_GROUP', 'FEATURE_GROUP_CODE', 'FEATURETYPECODE', 'NOTES', 'REVISION_NO', 'TREE_SPECIES', 'TREE_MODIFIED_RISK', 'CANOPY_SIZE_AT_MATURITY', 'SPONSORSHIP', 'SPONSORSHIP_PACKAGE', 'PLANTING_SEASON', 'PLANTING_FUNDER', 'PLANTING_NOTES', 'SPECIES_NOTES', 'TREE_TYPE', 'JOBS_REQUIRED', 'SERVICES_VISIBILITY', 'CONSTRAINTS', 'CANCELLATION_REASON', 'NOTES_FOR_STATUS', 'CANCELLATION_NOTES', 'created_user', 'created_date', 'last_edited_user', 'last_edited_date']\n",
      "\n",
      "Sample tree data:\n",
      "                    geometry  OBJECTID    ASSET_ID  \\\n",
      "0  POINT (-2.57807 51.48386)  20951518    00818916   \n",
      "1   POINT (-2.5784 51.48419)  20951519    00821743   \n",
      "2  POINT (-2.56105 51.47476)  20951520  PK00116904   \n",
      "3  POINT (-2.56024 51.47497)  20951521  PK00116901   \n",
      "4  POINT (-2.56031 51.47475)  20951522  PK00116902   \n",
      "\n",
      "                                 SITE_NAME   PLOT_NO FEATURE_ID LOCATION  \\\n",
      "0  Dovercourt Road To Muller Road Footpath  200001.0     FRAEXE     None   \n",
      "1  Dovercourt Road To Muller Road Footpath  200002.0                None   \n",
      "2      Eastville Roundabout M32 Junction 2  200005.0                None   \n",
      "3      Eastville Roundabout M32 Junction 2  200002.0                None   \n",
      "4      Eastville Roundabout M32 Junction 2  200003.0                None   \n",
      "\n",
      "                             TYPE  PRIM_MEAS    UNIT SITE_CODE FEAT_GP  \\\n",
      "0  PK: Tree - Parks and Green Spa          1  Number   4513696      TR   \n",
      "1  PK: Tree - Parks and Green Spa          3  Number   4513696      TR   \n",
      "2     PK: Tree - Highways Adopted          1  Number   4513795      TR   \n",
      "3     PK: Tree - Highways Adopted          1  Number   4513795      TR   \n",
      "4     PK: Tree - Highways Adopted          1  Number   4513795      TR   \n",
      "\n",
      "           X          Y DEAD CLASSIFICATION  EXTENT_EASTING_1  \\\n",
      "0  359956.40  176260.01    N             01         359956.40   \n",
      "1  359933.76  176296.56    N           RY04         359933.76   \n",
      "2  361130.01  175238.29    N           RY03         361130.01   \n",
      "3  361186.30  175261.56    N           RY04         361186.30   \n",
      "4  361181.52  175236.67    N           RY04         361181.52   \n",
      "\n",
      "   EXTENT_NORTHING_1  EXTENT_EASTING_2  EXTENT_NORTHING_2  LAYERS LATIN_CODE  \\\n",
      "0          176260.01         359956.40          176260.01  FRAEXE       FREX   \n",
      "1          176296.56         359933.76          176296.56               PRZZ   \n",
      "2          175238.29         361130.01          175238.29               MEGL   \n",
      "3          175261.56         361186.30          175261.56               MEGL   \n",
      "4          175236.67         361181.52          175236.67               MEGL   \n",
      "\n",
      "                     LATIN_NAME FEATURE_TYPE_NAME   COMMON_NAME  \\\n",
      "0            Fraxinus excelsior              None           Ash   \n",
      "1      Prunus - Species Unknown              None        Cherry   \n",
      "2  Metasequoia glyptostroboides              None  Dawn Redwood   \n",
      "3  Metasequoia glyptostroboides              None  Dawn Redwood   \n",
      "4  Metasequoia glyptostroboides              None  Dawn Redwood   \n",
      "\n",
      "      FULL_COMMON_NAME       CROWN_HEIGHT        CROWN_WIDTH  \\\n",
      "0           Common ash          15 Metres          14 Metres   \n",
      "1  Unidentified cherry  No Code Allocated  No Code Allocated   \n",
      "2         Dawn redwood           6 Metres           4 Metres   \n",
      "3         Dawn redwood           4 Metres           1 Metres   \n",
      "4         Dawn redwood           4 Metres           1 Metres   \n",
      "\n",
      "            CROWN_AREA                DBH LOCATION_RISK_ZONE EPICORMIC  \\\n",
      "0                       No Code Allocated    Risk Zone D (5)             \n",
      "1                       No Code Allocated    Risk Zone D (5)             \n",
      "2  20.1 - 100 M2 (New)     10 Centimetres    Risk Zone A (2)             \n",
      "3    Up to 20 M2 (New)      7 Centimetres    Risk Zone B (3)             \n",
      "4    Up to 20 M2 (New)      6 Centimetres    Risk Zone B (3)             \n",
      "\n",
      "  INSURANCE_CLAIM_HISTORY CENTRAL_ASSET_ID CONTRACT_AREA_NAME CUSTOMER  \\\n",
      "0       No Code Allocated         00818916               None     None   \n",
      "1       No Code Allocated         00821743               None     None   \n",
      "2       No Code Allocated       PK00116904               None     None   \n",
      "3       No Code Allocated       PK00116901               None     None   \n",
      "4       No Code Allocated       PK00116902               None     None   \n",
      "\n",
      "  DEAD_FLAG FEATURE_GROUP FEATURE_GROUP_CODE FEATURETYPECODE NOTES  \\\n",
      "0         N          None                 TR            None  None   \n",
      "1         N          None                 TR            None  None   \n",
      "2         N          None                 TR            None  None   \n",
      "3         N          None                 TR            None  None   \n",
      "4         N          None                 TR            None  None   \n",
      "\n",
      "  REVISION_NO                  TREE_SPECIES TREE_MODIFIED_RISK  \\\n",
      "0        None            Fraxinus excelsior    Risk Zone D (5)   \n",
      "1        None      Prunus - Species Unknown    Risk Zone D (5)   \n",
      "2        None  Metasequoia glyptostroboides    Risk Zone A (2)   \n",
      "3        None  Metasequoia glyptostroboides    Risk Zone B (3)   \n",
      "4        None  Metasequoia glyptostroboides    Risk Zone B (3)   \n",
      "\n",
      "  CANOPY_SIZE_AT_MATURITY SPONSORSHIP SPONSORSHIP_PACKAGE PLANTING_SEASON  \\\n",
      "0                    None        None                None            None   \n",
      "1                    None        None                None            None   \n",
      "2                    None        None                None            None   \n",
      "3                    None        None                None            None   \n",
      "4                    None        None                None            None   \n",
      "\n",
      "  PLANTING_FUNDER PLANTING_NOTES SPECIES_NOTES TREE_TYPE JOBS_REQUIRED  \\\n",
      "0            None           None          None      None          None   \n",
      "1            None           None          None      None          None   \n",
      "2            None           None          None      None          None   \n",
      "3            None           None          None      None          None   \n",
      "4            None           None          None      None          None   \n",
      "\n",
      "  SERVICES_VISIBILITY CONSTRAINTS CANCELLATION_REASON NOTES_FOR_STATUS  \\\n",
      "0                None        None                None             None   \n",
      "1                None        None                None             None   \n",
      "2                None        None                None             None   \n",
      "3                None        None                None             None   \n",
      "4                None        None                None             None   \n",
      "\n",
      "  CANCELLATION_NOTES created_user   created_date last_edited_user  \\\n",
      "0               None   PARKS_EDIT  1764306015000       PARKS_EDIT   \n",
      "1               None   PARKS_EDIT  1764306015000       PARKS_EDIT   \n",
      "2               None   PARKS_EDIT  1764306015000       PARKS_EDIT   \n",
      "3               None   PARKS_EDIT  1764306015000       PARKS_EDIT   \n",
      "4               None   PARKS_EDIT  1764306015000       PARKS_EDIT   \n",
      "\n",
      "   last_edited_date  \n",
      "0     1764306015000  \n",
      "1     1764306015000  \n",
      "2     1764306015000  \n",
      "3     1764306015000  \n",
      "4     1764306015000  \n",
      "\n",
      "Geometry types: ['Point']\n"
     ]
    }
   ],
   "source": [
    "def collect_tree_data(north, south, east, west):\n",
    "    \"\"\"\n",
    "    Collect tree data from Bristol City Council API.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    north, south, east, west : float\n",
    "        Bounding box coordinates (used for filtering if needed)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    geopandas.GeoDataFrame\n",
    "        Tree features from Bristol API\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Bristol tree data API endpoint (using GeoJSON format)\n",
    "        api_url = \"https://maps2.bristol.gov.uk/server2/rest/services/ext/ll_environment_and_planning/MapServer/32/query\"\n",
    "        \n",
    "        print(\"Fetching tree data from Bristol City Council API...\")\n",
    "        \n",
    "        # First, get the total count\n",
    "        count_params = {\n",
    "            'where': '1=1',\n",
    "            'returnCountOnly': 'true',\n",
    "            'f': 'json'\n",
    "        }\n",
    "        \n",
    "        count_response = requests.get(api_url, params=count_params, timeout=30)\n",
    "        count_response.raise_for_status()\n",
    "        total_count = count_response.json().get('count', 0)\n",
    "        print(f\"Total records available: {total_count}\")\n",
    "        \n",
    "        # Fetch all records using pagination\n",
    "        all_features = []\n",
    "        batch_size = 1000  # API limit per request\n",
    "        offset = 0\n",
    "        \n",
    "        while offset < total_count:\n",
    "            params = {\n",
    "                'where': '1=1',\n",
    "                'outFields': '*',\n",
    "                'f': 'geojson',\n",
    "                'resultOffset': offset,\n",
    "                'resultRecordCount': batch_size\n",
    "            }\n",
    "            \n",
    "            print(f\"Fetching records {offset} to {min(offset + batch_size, total_count)}...\")\n",
    "            response = requests.get(api_url, params=params, timeout=60)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            data = response.json()\n",
    "            \n",
    "            if 'features' in data and len(data['features']) > 0:\n",
    "                all_features.extend(data['features'])\n",
    "                offset += len(data['features'])\n",
    "            else:\n",
    "                break\n",
    "        \n",
    "        print(f\"Successfully fetched {len(all_features)} total features\")\n",
    "        \n",
    "        # Convert all features to GeoDataFrame\n",
    "        if len(all_features) > 0:\n",
    "            # Create a GeoJSON structure\n",
    "            geojson_data = {\n",
    "                'type': 'FeatureCollection',\n",
    "                'features': all_features\n",
    "            }\n",
    "            \n",
    "            # Create GeoDataFrame directly from GeoJSON\n",
    "            trees_gdf = gpd.GeoDataFrame.from_features(geojson_data, crs='EPSG:4326')\n",
    "            \n",
    "            # Filter to bounding box\n",
    "            trees_gdf = trees_gdf.cx[west:east, south:north]\n",
    "            \n",
    "            print(f\"Collected {len(trees_gdf)} tree features within study area\")\n",
    "            print(f\"Available columns: {trees_gdf.columns.tolist()}\")\n",
    "            return trees_gdf\n",
    "        else:\n",
    "            print(\"No tree features found in API response\")\n",
    "            return gpd.GeoDataFrame()\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error collecting tree data: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        # Return empty GeoDataFrame if collection fails\n",
    "        return gpd.GeoDataFrame()\n",
    "\n",
    "# Collect tree data\n",
    "tree_data = collect_tree_data(\n",
    "    BRISTOL_BOUNDS['north'],\n",
    "    BRISTOL_BOUNDS['south'],\n",
    "    BRISTOL_BOUNDS['east'],\n",
    "    BRISTOL_BOUNDS['west']\n",
    ")\n",
    "\n",
    "if not tree_data.empty:\n",
    "    print(f\"\\nTree data shape: {tree_data.shape}\")\n",
    "    print(f\"Tree data columns: {tree_data.columns.tolist()}\")\n",
    "    print(f\"\\nSample tree data:\")\n",
    "    print(tree_data.head())\n",
    "    \n",
    "    # Check geometry type\n",
    "    print(f\"\\nGeometry types: {tree_data.geometry.type.unique()}\")\n",
    "else:\n",
    "    print(\"\\nNo tree data available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "### 4.2 Building Data (OpenStreetMap)\n",
    "\n",
    "Fetches building footprints from OpenStreetMap via Overpass API.\n",
    "\n",
    "**Performance by study area size:**\n",
    "- TINY (~0.25 km¬≤): ~10-30 seconds\n",
    "- TEST (~4 km¬≤): ~1-3 minutes  \n",
    "- FULL (~180 km¬≤): ~5-15 minutes\n",
    "\n",
    "**Note:** For large areas, data is fetched directly from Overpass API mirrors with automatic failover."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching buildings for area: ~295.70 km¬≤\n",
      "Bounding box: N=51.5200, S=51.4000, E=-2.5000, W=-2.7000\n",
      "\n",
      "[Method 1] Using Overpass API directly...\n",
      "  Trying overpass-api.de...\n",
      "  ‚úì Success!\n",
      "\n",
      "‚úì Retrieved 227769 building elements from Overpass API\n",
      "  ‚úì Success!\n",
      "\n",
      "‚úì Retrieved 227769 building elements from Overpass API\n",
      "‚úì Created GeoDataFrame with 227578 buildings\n",
      "\n",
      "Building data shape: (227578, 5)\n",
      "Building data columns: ['geometry', 'building', 'osm_id', 'building_levels', 'name']...\n",
      "‚úì Created GeoDataFrame with 227578 buildings\n",
      "\n",
      "Building data shape: (227578, 5)\n",
      "Building data columns: ['geometry', 'building', 'osm_id', 'building_levels', 'name']...\n"
     ]
    }
   ],
   "source": [
    "def collect_building_data(north, south, east, west, skip=False, method='overpass_direct'):\n",
    "    \"\"\"\n",
    "    Collect building data from OpenStreetMap.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    north, south, east, west : float\n",
    "        Bounding box coordinates\n",
    "    skip : bool\n",
    "        If True, skip building data collection and return empty GeoDataFrame\n",
    "    method : str\n",
    "        'overpass_direct' - Direct Overpass API calls (fastest, most reliable)\n",
    "        'osmnx' - Use OSMnx library (slower fallback)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    geopandas.GeoDataFrame\n",
    "        Building features\n",
    "    \"\"\"\n",
    "    if skip:\n",
    "        print(\"Skipping building data collection (skip=True)\")\n",
    "        print(\"Analysis will continue without building density factor\")\n",
    "        return gpd.GeoDataFrame()\n",
    "    \n",
    "    # Calculate approximate area\n",
    "    area_deg = abs(north - south) * abs(east - west)\n",
    "    area_km = area_deg * 111 * 111\n",
    "    print(f\"Fetching buildings for area: ~{area_km:.2f} km¬≤\")\n",
    "    print(f\"Bounding box: N={north:.4f}, S={south:.4f}, E={east:.4f}, W={west:.4f}\")\n",
    "    \n",
    "    # Method 1: Direct Overpass API (RECOMMENDED - faster and more reliable)\n",
    "    if method == 'overpass_direct':\n",
    "        try:\n",
    "            print(\"\\n[Method 1] Using Overpass API directly...\")\n",
    "            \n",
    "            # List of Overpass API mirrors for redundancy\n",
    "            overpass_urls = [\n",
    "                \"https://overpass-api.de/api/interpreter\",\n",
    "                \"https://overpass.kumi.systems/api/interpreter\",\n",
    "                \"https://overpass.openstreetmap.ru/api/interpreter\"\n",
    "            ]\n",
    "            \n",
    "            # Optimized Overpass QL query - gets only essential data\n",
    "            query = f\"\"\"\n",
    "            [out:json][timeout:60];\n",
    "            (\n",
    "              way[\"building\"]({south},{west},{north},{east});\n",
    "              relation[\"building\"]({south},{west},{north},{east});\n",
    "            );\n",
    "            out geom;\n",
    "            \"\"\"\n",
    "            \n",
    "            buildings_data = None\n",
    "            \n",
    "            for api_url in overpass_urls:\n",
    "                try:\n",
    "                    print(f\"  Trying {api_url.split('/')[2]}...\")\n",
    "                    response = requests.post(\n",
    "                        api_url, \n",
    "                        data=query, \n",
    "                        timeout=90,\n",
    "                        headers={'User-Agent': 'SubsidenceRiskAnalysis/1.0'}\n",
    "                    )\n",
    "                    \n",
    "                    if response.status_code == 200:\n",
    "                        buildings_data = response.json()\n",
    "                        print(f\"  ‚úì Success!\")\n",
    "                        break\n",
    "                    else:\n",
    "                        print(f\"  ‚úó HTTP {response.status_code}\")\n",
    "                        continue\n",
    "                        \n",
    "                except requests.exceptions.Timeout:\n",
    "                    print(f\"  ‚úó Timeout\")\n",
    "                    continue\n",
    "                except Exception as e:\n",
    "                    print(f\"  ‚úó Error: {str(e)[:50]}\")\n",
    "                    continue\n",
    "            \n",
    "            if buildings_data and 'elements' in buildings_data:\n",
    "                elements = buildings_data['elements']\n",
    "                print(f\"\\n‚úì Retrieved {len(elements)} building elements from Overpass API\")\n",
    "                \n",
    "                # Convert Overpass JSON to GeoDataFrame\n",
    "                features = []\n",
    "                for element in elements:\n",
    "                    if 'geometry' in element:\n",
    "                        # Extract coordinates\n",
    "                        coords = [(node['lon'], node['lat']) for node in element['geometry']]\n",
    "                        if len(coords) >= 3:  # Valid polygon needs at least 3 points\n",
    "                            from shapely.geometry import Polygon\n",
    "                            poly = Polygon(coords)\n",
    "                            features.append({\n",
    "                                'geometry': poly,\n",
    "                                'building': element.get('tags', {}).get('building', 'yes'),\n",
    "                                'osm_id': element.get('id'),\n",
    "                                'building_levels': element.get('tags', {}).get('building:levels'),\n",
    "                                'name': element.get('tags', {}).get('name')\n",
    "                            })\n",
    "                \n",
    "                if features:\n",
    "                    buildings_gdf = gpd.GeoDataFrame(features, crs='EPSG:4326')\n",
    "                    print(f\"‚úì Created GeoDataFrame with {len(buildings_gdf)} buildings\")\n",
    "                    return buildings_gdf\n",
    "                else:\n",
    "                    print(\"‚úó No valid building polygons found\")\n",
    "                    return gpd.GeoDataFrame()\n",
    "            else:\n",
    "                print(\"‚úó All Overpass API mirrors failed or returned no data\")\n",
    "                print(\"  Falling back to OSMnx method...\")\n",
    "                method = 'osmnx'\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"‚úó Overpass direct method failed: {e}\")\n",
    "            print(\"  Falling back to OSMnx method...\")\n",
    "            method = 'osmnx'\n",
    "    \n",
    "    # Method 2: OSMnx (fallback, slower but sometimes works)\n",
    "    if method == 'osmnx':\n",
    "        try:\n",
    "            print(\"\\n[Method 2] Using OSMnx library...\")\n",
    "            print(\"  Note: This can take 5-20+ minutes for dense urban areas\")\n",
    "            \n",
    "            buildings_gdf = ox.features_from_bbox(\n",
    "                bbox=(north, south, east, west),\n",
    "                tags={'building': True}\n",
    "            )\n",
    "            \n",
    "            print(f\"‚úì Collected {len(buildings_gdf)} building features\")\n",
    "            return buildings_gdf\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚úó OSMnx method failed: {e}\")\n",
    "    \n",
    "    print(\"\\n‚úó All methods failed to retrieve building data\")\n",
    "    print(\"\\nRECOMMENDATIONS:\")\n",
    "    print(\"1. Set skip=True to run analysis without buildings\")\n",
    "    print(\"2. Load pre-collected data: gpd.read_file('bristol_buildings_tiny.geojson')\")\n",
    "    print(\"3. Try again later when Overpass API is less busy\")\n",
    "    \n",
    "    return gpd.GeoDataFrame()\n",
    "\n",
    "# ============================================\n",
    "# OPTION 1: Load pre-collected data (RECOMMENDED - instant, proven to work)\n",
    "# ============================================\n",
    "# Uncomment to use pre-collected building data:\n",
    "# building_data = gpd.read_file('bristol_buildings_tiny.geojson')\n",
    "# print(f\"‚úì Loaded {len(building_data)} buildings from file\")\n",
    "\n",
    "# ============================================\n",
    "# OPTION 2: Collect from API in notebook (may timeout in notebook environment)\n",
    "# ============================================\n",
    "# Comment out if using Option 1 above\n",
    "SKIP_BUILDINGS = False  # Set True to skip building collection entirely\n",
    "\n",
    "building_data = collect_building_data(\n",
    "    BRISTOL_BOUNDS['north'],\n",
    "    BRISTOL_BOUNDS['south'],\n",
    "    BRISTOL_BOUNDS['east'],\n",
    "    BRISTOL_BOUNDS['west'],\n",
    "    skip=SKIP_BUILDINGS,\n",
    "    method='overpass_direct'  # Options: 'overpass_direct', 'osmnx'\n",
    ")\n",
    "\n",
    "if not building_data.empty:\n",
    "    print(f\"\\nBuilding data shape: {building_data.shape}\")\n",
    "    print(f\"Building data columns: {building_data.columns.tolist()[:10]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5202ad43",
   "metadata": {},
   "source": [
    "### 4.3 Soil Data (British Geological Survey WMS)\n",
    "\n",
    "Fetches soil texture data from the BGS UK Soil Observatory WMS service.\n",
    "\n",
    "**Data source:** `Parent.Material.Soil.texture` layer from BGS\n",
    "\n",
    "**How it works:**\n",
    "1. Area is split into a grid of tiles (~1.6km √ó 1.5km each)\n",
    "2. Each tile is fetched separately to handle large areas\n",
    "3. Tiles are stitched into a single raster\n",
    "4. Soil types are classified from raster colors:\n",
    "   - Light colors ‚Üí Sandy soils (low risk)\n",
    "   - Dark/brown colors ‚Üí Clay soils (high risk)\n",
    "\n",
    "**Note:** Areas where BGS returns no data are marked as \"Unknown\" and receive a soil score of 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "46f51738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "INITIALIZING SOIL RASTER DATA\n",
      "============================================================\n",
      "Fetching soil raster from BGS WMS (tiled mode)...\n",
      "  Layer: Parent.Material.Soil.texture\n",
      "  Grid: 14√ó9 tiles (126 total requests)\n",
      "  Tile size: ~1.6km √ó 1.5km\n",
      "  Layer: Parent.Material.Soil.texture\n",
      "  Grid: 14√ó9 tiles (126 total requests)\n",
      "  Tile size: ~1.6km √ó 1.5km\n",
      "  Progress: 100% (126 tiles with data)\n",
      "‚úì Fetched soil raster: (512, 512, 4)\n",
      "  Tiles with data: 126/126\n",
      "  Coverage: 96.9%\n",
      "  Soil type distribution:\n",
      "    Unknown: 3.1%\n",
      "    Sand: 35.5%\n",
      "    Sandy Loam: 61.1%\n",
      "    Loam: 0.3%\n",
      "\n",
      "‚úì Soil raster ready for building analysis\n",
      "  Progress: 100% (126 tiles with data)\n",
      "‚úì Fetched soil raster: (512, 512, 4)\n",
      "  Tiles with data: 126/126\n",
      "  Coverage: 96.9%\n",
      "  Soil type distribution:\n",
      "    Unknown: 3.1%\n",
      "    Sand: 35.5%\n",
      "    Sandy Loam: 61.1%\n",
      "    Loam: 0.3%\n",
      "\n",
      "‚úì Soil raster ready for building analysis\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# SOIL DATA HANDLER (with tiled fetching)\n",
    "# ============================================\n",
    "\n",
    "class SoilRasterHandler:\n",
    "    \"\"\"Handles BGS WMS soil data as a raster layer with tiled fetching for large areas.\"\"\"\n",
    "    \n",
    "    def __init__(self, bounds, resolution=512, tile_size=128):\n",
    "        \"\"\"\n",
    "        Initialize the soil raster handler.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        bounds : dict\n",
    "            Dictionary with 'north', 'south', 'east', 'west' keys\n",
    "        resolution : int\n",
    "            Total pixel resolution for the final raster image\n",
    "        tile_size : int\n",
    "            Size of each tile when fetching (smaller = more requests but better coverage)\n",
    "        \"\"\"\n",
    "        self.bounds = bounds\n",
    "        self.resolution = resolution\n",
    "        self.tile_size = tile_size\n",
    "        self.raster_array = None\n",
    "        self.transform = None\n",
    "        self.soil_type_map = None\n",
    "        \n",
    "    def fetch_wms_raster(self, use_real_data=False):\n",
    "        \"\"\"\n",
    "        Fetch soil data from BGS WMS and store as raster.\n",
    "        Uses tiled fetching to handle large areas that exceed WMS limits.\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        numpy.ndarray\n",
    "            Soil raster array\n",
    "        \"\"\"\n",
    "        if not use_real_data:\n",
    "            print(\"Generating synthetic soil raster (set use_real_data=True for BGS data)\")\n",
    "            return self._generate_synthetic_raster()\n",
    "        \n",
    "        try:\n",
    "            from owslib.wms import WebMapService\n",
    "            from PIL import Image\n",
    "            from io import BytesIO\n",
    "            \n",
    "            print(\"Fetching soil raster from BGS WMS (tiled mode)...\")\n",
    "            \n",
    "            wms_url = 'https://map.bgs.ac.uk/arcgis/services/UKSO/UKSO_BGS/MapServer/WMSServer'\n",
    "            wms = WebMapService(wms_url, version='1.3.0')\n",
    "            \n",
    "            # Find a queryable layer\n",
    "            preferred_layers = [\n",
    "                'Parent.Material.Soil.texture',\n",
    "                'Parent.Material.Soil.Wash',\n",
    "                'Peat.Coverage',\n",
    "                'Parent.Material.Grain.size',\n",
    "            ]\n",
    "            \n",
    "            layer_name = None\n",
    "            for candidate in preferred_layers:\n",
    "                if candidate in wms.contents:\n",
    "                    layer_obj = wms.contents[candidate]\n",
    "                    if getattr(layer_obj, 'queryable', 0) == 1:\n",
    "                        layer_name = candidate\n",
    "                        break\n",
    "            \n",
    "            if not layer_name:\n",
    "                raise Exception(\"No queryable layers found in WMS service\")\n",
    "            \n",
    "            print(f\"  Layer: {layer_name}\")\n",
    "            \n",
    "            # Calculate tile grid\n",
    "            width_deg = self.bounds['east'] - self.bounds['west']\n",
    "            height_deg = self.bounds['north'] - self.bounds['south']\n",
    "            \n",
    "            # Determine optimal tile count based on area size\n",
    "            # BGS WMS seems to have issues with requests covering > ~0.02 degrees\n",
    "            max_tile_deg = 0.015  # Max degrees per tile dimension\n",
    "            \n",
    "            n_tiles_x = max(1, int(np.ceil(width_deg / max_tile_deg)))\n",
    "            n_tiles_y = max(1, int(np.ceil(height_deg / max_tile_deg)))\n",
    "            \n",
    "            # Calculate tile dimensions in degrees\n",
    "            tile_width_deg = width_deg / n_tiles_x\n",
    "            tile_height_deg = height_deg / n_tiles_y\n",
    "            \n",
    "            # Calculate pixels per tile\n",
    "            pixels_per_tile_x = self.resolution // n_tiles_x\n",
    "            pixels_per_tile_y = self.resolution // n_tiles_y\n",
    "            \n",
    "            print(f\"  Grid: {n_tiles_x}√ó{n_tiles_y} tiles ({n_tiles_x * n_tiles_y} total requests)\")\n",
    "            print(f\"  Tile size: ~{tile_width_deg*111:.1f}km √ó {tile_height_deg*111:.1f}km\")\n",
    "            \n",
    "            # Initialize combined raster\n",
    "            combined_raster = np.zeros((self.resolution, self.resolution, 4), dtype=np.uint8)\n",
    "            combined_raster[:, :, 3] = 0  # Start fully transparent\n",
    "            \n",
    "            tiles_with_data = 0\n",
    "            tiles_empty = 0\n",
    "            \n",
    "            # Fetch each tile\n",
    "            for ty in range(n_tiles_y):\n",
    "                for tx in range(n_tiles_x):\n",
    "                    # Calculate tile bounds\n",
    "                    tile_west = self.bounds['west'] + tx * tile_width_deg\n",
    "                    tile_east = tile_west + tile_width_deg\n",
    "                    tile_north = self.bounds['north'] - ty * tile_height_deg\n",
    "                    tile_south = tile_north - tile_height_deg\n",
    "                    \n",
    "                    tile_bbox = (tile_west, tile_south, tile_east, tile_north)\n",
    "                    \n",
    "                    try:\n",
    "                        img = wms.getmap(\n",
    "                            layers=[layer_name],\n",
    "                            srs='EPSG:4326',\n",
    "                            bbox=tile_bbox,\n",
    "                            size=(pixels_per_tile_x, pixels_per_tile_y),\n",
    "                            format='image/png',\n",
    "                            transparent=True\n",
    "                        )\n",
    "                        \n",
    "                        img_data = Image.open(BytesIO(img.read()))\n",
    "                        tile_array = np.array(img_data)\n",
    "                        \n",
    "                        # Ensure RGBA format\n",
    "                        if tile_array.shape[-1] == 3:\n",
    "                            alpha = np.full(tile_array.shape[:2] + (1,), 255, dtype=np.uint8)\n",
    "                            tile_array = np.concatenate([tile_array, alpha], axis=-1)\n",
    "                        \n",
    "                        # Check if tile has real data (non-transparent)\n",
    "                        has_data = (tile_array[:, :, 3] > 0).any()\n",
    "                        \n",
    "                        if has_data:\n",
    "                            tiles_with_data += 1\n",
    "                        else:\n",
    "                            tiles_empty += 1\n",
    "                        \n",
    "                        # Calculate position in combined raster\n",
    "                        y_start = ty * pixels_per_tile_y\n",
    "                        y_end = y_start + pixels_per_tile_y\n",
    "                        x_start = tx * pixels_per_tile_x\n",
    "                        x_end = x_start + pixels_per_tile_x\n",
    "                        \n",
    "                        # Handle edge tiles that might be slightly different size\n",
    "                        actual_h, actual_w = tile_array.shape[:2]\n",
    "                        y_end = min(y_end, y_start + actual_h)\n",
    "                        x_end = min(x_end, x_start + actual_w)\n",
    "                        \n",
    "                        combined_raster[y_start:y_end, x_start:x_end] = tile_array[:y_end-y_start, :x_end-x_start]\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        tiles_empty += 1\n",
    "                        # Leave tile as transparent\n",
    "                \n",
    "                # Progress indicator\n",
    "                progress = ((ty * n_tiles_x + tx + 1) / (n_tiles_x * n_tiles_y)) * 100\n",
    "                print(f\"\\r  Progress: {progress:.0f}% ({tiles_with_data} tiles with data)\", end=\"\")\n",
    "            \n",
    "            print()  # New line after progress\n",
    "            \n",
    "            self.raster_array = combined_raster\n",
    "            \n",
    "            # Create geotransform for coordinate lookup\n",
    "            self.transform = {\n",
    "                'west': self.bounds['west'],\n",
    "                'north': self.bounds['north'],\n",
    "                'pixel_width': (self.bounds['east'] - self.bounds['west']) / self.resolution,\n",
    "                'pixel_height': (self.bounds['north'] - self.bounds['south']) / self.resolution\n",
    "            }\n",
    "            \n",
    "            # Check coverage\n",
    "            alpha_channel = self.raster_array[:, :, 3]\n",
    "            coverage_pct = (alpha_channel > 0).sum() / alpha_channel.size * 100\n",
    "            \n",
    "            print(f\"‚úì Fetched soil raster: {self.raster_array.shape}\")\n",
    "            print(f\"  Tiles with data: {tiles_with_data}/{n_tiles_x * n_tiles_y}\")\n",
    "            print(f\"  Coverage: {coverage_pct:.1f}%\")\n",
    "            \n",
    "            if coverage_pct < 10:\n",
    "                print(\"  ‚ö†Ô∏è Low coverage - area may be outside BGS soil data extent\")\n",
    "            \n",
    "            # Classify soil types from raster values\n",
    "            self._classify_soil_types()\n",
    "            \n",
    "            return self.raster_array\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚úó BGS WMS failed: {e}\")\n",
    "            print(\"  Generating synthetic raster...\")\n",
    "            return self._generate_synthetic_raster()\n",
    "    \n",
    "    def _generate_synthetic_raster(self):\n",
    "        \"\"\"Generate synthetic soil raster for testing.\"\"\"\n",
    "        np.random.seed(42)  # Reproducible\n",
    "        \n",
    "        # Create smooth soil variation using perlin-like noise\n",
    "        x = np.linspace(0, 4, self.resolution)\n",
    "        y = np.linspace(0, 4, self.resolution)\n",
    "        xx, yy = np.meshgrid(x, y)\n",
    "        \n",
    "        # Combine multiple frequencies for realistic variation\n",
    "        noise = (np.sin(xx * 2) * np.cos(yy * 2) + \n",
    "                 np.sin(xx * 4 + 1) * np.cos(yy * 4 + 1) * 0.5 +\n",
    "                 np.random.random((self.resolution, self.resolution)) * 0.3)\n",
    "        \n",
    "        # Normalize to 0-255 range\n",
    "        noise = ((noise - noise.min()) / (noise.max() - noise.min()) * 255).astype(np.uint8)\n",
    "        \n",
    "        # Create RGB image (grayscale for simplicity)\n",
    "        self.raster_array = np.stack([noise, noise, noise, np.full_like(noise, 255)], axis=-1)\n",
    "        \n",
    "        # Create geotransform\n",
    "        self.transform = {\n",
    "            'west': self.bounds['west'],\n",
    "            'north': self.bounds['north'],\n",
    "            'pixel_width': (self.bounds['east'] - self.bounds['west']) / self.resolution,\n",
    "            'pixel_height': (self.bounds['north'] - self.bounds['south']) / self.resolution\n",
    "        }\n",
    "        \n",
    "        print(f\"‚úì Generated synthetic soil raster: {self.raster_array.shape}\")\n",
    "        \n",
    "        # Classify soil types\n",
    "        self._classify_soil_types()\n",
    "        \n",
    "        return self.raster_array\n",
    "    \n",
    "    def _classify_soil_types(self):\n",
    "        \"\"\"Classify raster values into soil types, handling transparent pixels.\"\"\"\n",
    "        if self.raster_array is None:\n",
    "            return\n",
    "        \n",
    "        # Get grayscale value and alpha channel\n",
    "        if len(self.raster_array.shape) == 3:\n",
    "            gray = self.raster_array[:, :, 0].astype(float)\n",
    "            alpha = self.raster_array[:, :, 3]\n",
    "        else:\n",
    "            gray = self.raster_array.astype(float)\n",
    "            alpha = np.full_like(gray, 255)\n",
    "        \n",
    "        # Invert so higher values = more clay\n",
    "        clay_index = 255 - gray\n",
    "        \n",
    "        # Create soil type classification map\n",
    "        self.soil_type_map = np.zeros_like(clay_index, dtype=np.uint8)\n",
    "        \n",
    "        # Classify based on clay index thresholds\n",
    "        self.soil_type_map[clay_index < 40] = 1    # Sand\n",
    "        self.soil_type_map[(clay_index >= 40) & (clay_index < 80)] = 2    # Sandy Loam\n",
    "        self.soil_type_map[(clay_index >= 80) & (clay_index < 120)] = 3   # Loam\n",
    "        self.soil_type_map[(clay_index >= 120) & (clay_index < 160)] = 4  # Clay Loam\n",
    "        self.soil_type_map[(clay_index >= 160) & (clay_index < 200)] = 5  # Clay\n",
    "        self.soil_type_map[clay_index >= 200] = 6  # Heavy Clay\n",
    "        \n",
    "        # Mark transparent pixels (no data) as Unknown (code 0)\n",
    "        self.soil_type_map[alpha == 0] = 0\n",
    "        \n",
    "        # Mapping for lookup\n",
    "        self.soil_type_names = {\n",
    "            0: 'Unknown',\n",
    "            1: 'Sand',\n",
    "            2: 'Sandy Loam', \n",
    "            3: 'Loam',\n",
    "            4: 'Clay Loam',\n",
    "            5: 'Clay',\n",
    "            6: 'Heavy Clay'\n",
    "        }\n",
    "        \n",
    "        print(f\"  Soil type distribution:\")\n",
    "        unique, counts = np.unique(self.soil_type_map, return_counts=True)\n",
    "        for u, c in zip(unique, counts):\n",
    "            pct = c / self.soil_type_map.size * 100\n",
    "            name = self.soil_type_names.get(u, 'Unknown')\n",
    "            if pct > 0.1:  # Only show types with >0.1% coverage\n",
    "                print(f\"    {name}: {pct:.1f}%\")\n",
    "    \n",
    "    def get_soil_at_point(self, lon, lat):\n",
    "        \"\"\"\n",
    "        Get soil type at a specific coordinate.\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        tuple: (soil_type_code, soil_type_name, clay_index)\n",
    "        \"\"\"\n",
    "        if self.raster_array is None or self.transform is None:\n",
    "            return (0, 'Unknown', 0)\n",
    "        \n",
    "        # Convert lon/lat to pixel coordinates\n",
    "        px = int((lon - self.transform['west']) / self.transform['pixel_width'])\n",
    "        py = int((self.transform['north'] - lat) / self.transform['pixel_height'])\n",
    "        \n",
    "        # Clamp to bounds\n",
    "        px = max(0, min(px, self.resolution - 1))\n",
    "        py = max(0, min(py, self.resolution - 1))\n",
    "        \n",
    "        soil_code = self.soil_type_map[py, px]\n",
    "        soil_name = self.soil_type_names.get(soil_code, 'Unknown')\n",
    "        \n",
    "        # Get clay index value\n",
    "        if len(self.raster_array.shape) == 3:\n",
    "            clay_index = 255 - self.raster_array[py, px, 0]\n",
    "        else:\n",
    "            clay_index = 255 - self.raster_array[py, px]\n",
    "        \n",
    "        return (soil_code, soil_name, clay_index)\n",
    "    \n",
    "    def get_raster_for_folium(self):\n",
    "        \"\"\"\n",
    "        Get raster data formatted for folium ImageOverlay.\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        tuple: (image_bounds, colored_array)\n",
    "        \"\"\"\n",
    "        if self.soil_type_map is None:\n",
    "            return None, None\n",
    "        \n",
    "        # Create colored version of soil map\n",
    "        colors = {\n",
    "            0: [200, 200, 200, 100],  # Unknown - light gray, semi-transparent\n",
    "            1: [255, 255, 200, 180],  # Sand - pale yellow\n",
    "            2: [255, 230, 150, 180],  # Sandy Loam - light orange\n",
    "            3: [200, 200, 150, 180],  # Loam - tan\n",
    "            4: [180, 150, 100, 180],  # Clay Loam - brown\n",
    "            5: [150, 100, 80, 180],   # Clay - dark brown\n",
    "            6: [100, 60, 40, 180]     # Heavy Clay - dark brown/red\n",
    "        }\n",
    "        \n",
    "        colored = np.zeros((self.resolution, self.resolution, 4), dtype=np.uint8)\n",
    "        for code, color in colors.items():\n",
    "            mask = self.soil_type_map == code\n",
    "            colored[mask] = color\n",
    "        \n",
    "        bounds = [[self.bounds['south'], self.bounds['west']], \n",
    "                  [self.bounds['north'], self.bounds['east']]]\n",
    "        \n",
    "        return bounds, colored\n",
    "\n",
    "# Initialize soil raster handler\n",
    "print(\"=\" * 60)\n",
    "print(\"INITIALIZING SOIL RASTER DATA\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "USE_REAL_BGS_DATA = True  # Set True for real BGS WMS data\n",
    "\n",
    "soil_handler = SoilRasterHandler(BRISTOL_BOUNDS, resolution=512)\n",
    "soil_raster = soil_handler.fetch_wms_raster(use_real_data=USE_REAL_BGS_DATA)\n",
    "\n",
    "print(f\"\\n‚úì Soil raster ready for building analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1983558",
   "metadata": {},
   "source": [
    "## 5. Risk Scoring Functions\n",
    "\n",
    "This section implements the building-level subsidence risk scoring system:\n",
    "\n",
    "1. **Soil Scoring** - Samples soil type at building centroid and corners\n",
    "2. **Tree Scoring** - Uses R-tree spatial index for fast proximity queries\n",
    "3. **Combined Scoring** - Weighted combination with configurable thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ffb9b6a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Soil risk scoring functions loaded (using config from above)\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# SOIL RISK SCORING FUNCTIONS\n",
    "# ============================================\n",
    "# Note: SOIL_RISK_SCORES and SOIL_CODE_SCORES are defined in the \n",
    "# Risk Scoring Configuration cell above\n",
    "\n",
    "def get_soil_risk_score(soil_code):\n",
    "    \"\"\"\n",
    "    Get the subsidence risk score for a soil type.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    soil_code : int\n",
    "        Soil type code from raster classification\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    float\n",
    "        Risk score (0-10)\n",
    "    \"\"\"\n",
    "    return SOIL_CODE_SCORES.get(soil_code, 5.0)\n",
    "\n",
    "def get_building_soil_score(building_geom, soil_handler):\n",
    "    \"\"\"\n",
    "    Calculate soil risk score for a building.\n",
    "    \n",
    "    Samples soil at building centroid and optionally at corners.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    building_geom : shapely.geometry\n",
    "        Building polygon geometry\n",
    "    soil_handler : SoilRasterHandler\n",
    "        Soil data handler\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Soil analysis results including score, type, and details\n",
    "    \"\"\"\n",
    "    # Get building centroid\n",
    "    centroid = building_geom.centroid\n",
    "    \n",
    "    # Sample soil at centroid\n",
    "    soil_code, soil_name, clay_index = soil_handler.get_soil_at_point(centroid.x, centroid.y)\n",
    "    \n",
    "    # Get base score\n",
    "    soil_score = get_soil_risk_score(soil_code)\n",
    "    \n",
    "    # Optionally sample at building corners and average\n",
    "    if hasattr(building_geom, 'exterior'):\n",
    "        coords = list(building_geom.exterior.coords)\n",
    "        corner_scores = []\n",
    "        for x, y in coords[:4]:  # Sample up to 4 corners\n",
    "            code, _, _ = soil_handler.get_soil_at_point(x, y)\n",
    "            corner_scores.append(get_soil_risk_score(code))\n",
    "        \n",
    "        if corner_scores:\n",
    "            # Weighted average: 60% centroid, 40% corners\n",
    "            avg_corner = np.mean(corner_scores)\n",
    "            soil_score = soil_score * 0.6 + avg_corner * 0.4\n",
    "    \n",
    "    return {\n",
    "        'soil_score': soil_score,\n",
    "        'soil_type': soil_name,\n",
    "        'soil_code': soil_code,\n",
    "        'clay_index': clay_index\n",
    "    }\n",
    "\n",
    "print(\"‚úì Soil risk scoring functions loaded (using config from above)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "82642b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Building spatial index for 55,235 trees...\n",
      "  ‚úì Spatial index built\n",
      "‚úì Tree proximity risk scoring functions loaded (with spatial index optimization)\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# TREE PROXIMITY RISK SCORING FUNCTIONS (OPTIMIZED)\n",
    "# ============================================\n",
    "# Note: TREE_CONFIG and SPECIES_RISK_FACTORS are defined in the \n",
    "# Risk Scoring Configuration cell above\n",
    "\n",
    "# Build spatial index for fast tree lookups\n",
    "_tree_sindex = None\n",
    "_tree_data_indexed = None\n",
    "\n",
    "def build_tree_spatial_index(tree_data):\n",
    "    \"\"\"Build a spatial index for fast tree proximity lookups.\"\"\"\n",
    "    global _tree_sindex, _tree_data_indexed\n",
    "    \n",
    "    if tree_data is None or tree_data.empty:\n",
    "        _tree_sindex = None\n",
    "        _tree_data_indexed = None\n",
    "        return\n",
    "    \n",
    "    print(f\"  Building spatial index for {len(tree_data):,} trees...\")\n",
    "    _tree_data_indexed = tree_data.copy()\n",
    "    _tree_sindex = tree_data.sindex  # R-tree spatial index\n",
    "    print(f\"  ‚úì Spatial index built\")\n",
    "\n",
    "def get_species_factor(species_name):\n",
    "    \"\"\"\n",
    "    Get the risk factor for a tree species.\n",
    "    \"\"\"\n",
    "    if pd.isna(species_name) or not species_name:\n",
    "        return SPECIES_RISK_FACTORS['default']\n",
    "    \n",
    "    species_lower = str(species_name).lower()\n",
    "    \n",
    "    for key, factor in SPECIES_RISK_FACTORS.items():\n",
    "        if key in species_lower:\n",
    "            return factor\n",
    "    \n",
    "    return SPECIES_RISK_FACTORS['default']\n",
    "\n",
    "def calculate_tree_influence(tree_row, building_centroid, crs='EPSG:4326'):\n",
    "    \"\"\"\n",
    "    Calculate the influence of a single tree on a building.\n",
    "    \"\"\"\n",
    "    tree_point = tree_row.geometry\n",
    "    \n",
    "    # Calculate distance (in degrees, convert to approximate meters)\n",
    "    dist_deg = tree_point.distance(building_centroid)\n",
    "    dist_m = dist_deg * 111000  # Rough conversion at UK latitude\n",
    "    \n",
    "    # Get crown width (proxy for root spread) - convert to float if string\n",
    "    crown_width = tree_row.get('CROWN_WIDTH', TREE_CONFIG['default_crown_width_m'])\n",
    "    try:\n",
    "        crown_width = float(crown_width) if crown_width is not None else TREE_CONFIG['default_crown_width_m']\n",
    "    except (ValueError, TypeError):\n",
    "        crown_width = TREE_CONFIG['default_crown_width_m']\n",
    "    if pd.isna(crown_width) or crown_width <= 0:\n",
    "        crown_width = TREE_CONFIG['default_crown_width_m']\n",
    "    \n",
    "    # Estimate root spread zone\n",
    "    root_spread = crown_width * TREE_CONFIG['root_spread_multiplier']\n",
    "    \n",
    "    # Get species factor\n",
    "    species_name = tree_row.get('COMMON_NAME', tree_row.get('LATIN_NAME', ''))\n",
    "    species_factor = get_species_factor(species_name)\n",
    "    \n",
    "    # Get DBH - convert to float if string\n",
    "    dbh = tree_row.get('DBH', 0)\n",
    "    try:\n",
    "        dbh = float(dbh) if dbh is not None else 0\n",
    "    except (ValueError, TypeError):\n",
    "        dbh = 0\n",
    "    if pd.isna(dbh):\n",
    "        dbh = 0\n",
    "    dbh_factor = 1.0 + (dbh / 100) if dbh > 0 else 1.0\n",
    "    \n",
    "    # Calculate influence - designed to produce meaningful 0-10 scores\n",
    "    if dist_m <= 0:\n",
    "        dist_m = 0.1\n",
    "    \n",
    "    max_dist = TREE_CONFIG['max_influence_distance_m']\n",
    "    \n",
    "    if dist_m > max_dist:\n",
    "        influence = 0\n",
    "    elif dist_m <= root_spread:\n",
    "        # Within root zone - HIGH influence\n",
    "        # Base score of 3.0 for being in root zone, scaling up for closer trees\n",
    "        proximity_factor = 1 - (dist_m / root_spread) ** 0.5  # 0 to 1, higher when closer\n",
    "        influence = TREE_CONFIG['base_tree_score'] * (0.5 + 0.5 * proximity_factor) * species_factor * dbh_factor\n",
    "        \n",
    "        # Bonus for very close trees (< 5m)\n",
    "        if dist_m < 5:\n",
    "            influence += TREE_CONFIG['close_tree_bonus'] * (1 - dist_m / 5)\n",
    "    else:\n",
    "        # Outside root zone but within influence distance - decreasing influence\n",
    "        # Linear decay from root_spread to max_influence_distance\n",
    "        remaining_dist = max_dist - root_spread\n",
    "        dist_beyond_root = dist_m - root_spread\n",
    "        decay_factor = 1 - (dist_beyond_root / remaining_dist) ** TREE_CONFIG['distance_decay_power']\n",
    "        influence = 1.5 * decay_factor * species_factor * dbh_factor\n",
    "    \n",
    "    return {\n",
    "        'distance_m': dist_m,\n",
    "        'crown_width': crown_width,\n",
    "        'root_spread': root_spread,\n",
    "        'species_factor': species_factor,\n",
    "        'influence': influence,\n",
    "        'within_root_zone': dist_m <= root_spread\n",
    "    }\n",
    "\n",
    "def get_building_tree_score(building_geom, tree_data, max_trees=None):\n",
    "    \"\"\"\n",
    "    Calculate total tree proximity risk score for a building.\n",
    "    Uses spatial index for fast lookups.\n",
    "    \"\"\"\n",
    "    global _tree_sindex, _tree_data_indexed\n",
    "    \n",
    "    if tree_data is None or tree_data.empty:\n",
    "        return {\n",
    "            'tree_score': 0,\n",
    "            'nearby_trees': 0,\n",
    "            'trees_in_root_zone': 0,\n",
    "            'closest_tree_m': None,\n",
    "            'tree_details': []\n",
    "        }\n",
    "    \n",
    "    max_trees = max_trees or TREE_CONFIG['max_trees_to_consider']\n",
    "    \n",
    "    # Get building centroid\n",
    "    centroid = building_geom.centroid\n",
    "    \n",
    "    # Find nearby trees using spatial index (MUCH faster)\n",
    "    max_dist_deg = TREE_CONFIG['max_influence_distance_m'] / 111000\n",
    "    \n",
    "    # Create search bounding box\n",
    "    search_bbox = (\n",
    "        centroid.x - max_dist_deg,\n",
    "        centroid.y - max_dist_deg,\n",
    "        centroid.x + max_dist_deg,\n",
    "        centroid.y + max_dist_deg\n",
    "    )\n",
    "    \n",
    "    # Use spatial index if available\n",
    "    if _tree_sindex is not None and _tree_data_indexed is not None:\n",
    "        # Query spatial index - returns indices of potentially matching trees\n",
    "        possible_matches_idx = list(_tree_sindex.intersection(search_bbox))\n",
    "        if not possible_matches_idx:\n",
    "            return {\n",
    "                'tree_score': 0,\n",
    "                'nearby_trees': 0,\n",
    "                'trees_in_root_zone': 0,\n",
    "                'closest_tree_m': None,\n",
    "                'tree_details': []\n",
    "            }\n",
    "        nearby_trees = _tree_data_indexed.iloc[possible_matches_idx].head(max_trees)\n",
    "    else:\n",
    "        # Fallback to slower method\n",
    "        nearby_mask = (\n",
    "            (tree_data.geometry.x >= search_bbox[0]) & \n",
    "            (tree_data.geometry.x <= search_bbox[2]) &\n",
    "            (tree_data.geometry.y >= search_bbox[1]) & \n",
    "            (tree_data.geometry.y <= search_bbox[3])\n",
    "        )\n",
    "        nearby_trees = tree_data[nearby_mask].head(max_trees)\n",
    "    \n",
    "    if nearby_trees.empty:\n",
    "        return {\n",
    "            'tree_score': 0,\n",
    "            'nearby_trees': 0,\n",
    "            'trees_in_root_zone': 0,\n",
    "            'closest_tree_m': None,\n",
    "            'tree_details': []\n",
    "        }\n",
    "    \n",
    "    # Calculate influence from each tree\n",
    "    total_influence = 0\n",
    "    trees_in_root_zone = 0\n",
    "    closest_distance = float('inf')\n",
    "    tree_details = []\n",
    "    \n",
    "    for idx, tree in nearby_trees.iterrows():\n",
    "        result = calculate_tree_influence(tree, centroid)\n",
    "        \n",
    "        total_influence += result['influence']\n",
    "        \n",
    "        if result['within_root_zone']:\n",
    "            trees_in_root_zone += 1\n",
    "        \n",
    "        if result['distance_m'] < closest_distance:\n",
    "            closest_distance = result['distance_m']\n",
    "        \n",
    "        if result['influence'] > 0.1:\n",
    "            tree_details.append({\n",
    "                'tree_id': tree.get('ASSET_ID', idx),\n",
    "                'species': tree.get('COMMON_NAME', 'Unknown'),\n",
    "                'distance_m': result['distance_m'],\n",
    "                'influence': result['influence']\n",
    "            })\n",
    "    \n",
    "    # Cap the tree score - with new scoring, total_influence is already on ~0-10 scale\n",
    "    tree_score = min(TREE_CONFIG['score_cap'], total_influence)\n",
    "    \n",
    "    return {\n",
    "        'tree_score': tree_score,\n",
    "        'nearby_trees': len(nearby_trees),\n",
    "        'trees_in_root_zone': trees_in_root_zone,\n",
    "        'closest_tree_m': closest_distance if closest_distance < float('inf') else None,\n",
    "        'total_influence': total_influence,\n",
    "        'tree_details': sorted(tree_details, key=lambda x: x['influence'], reverse=True)[:5]\n",
    "    }\n",
    "\n",
    "# Build the spatial index now if tree data is available\n",
    "if 'tree_data' in dir() and tree_data is not None and not tree_data.empty:\n",
    "    build_tree_spatial_index(tree_data)\n",
    "\n",
    "print(\"‚úì Tree proximity risk scoring functions loaded (with spatial index optimization)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e72b4fea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Combined risk scoring functions loaded (using config from above)\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# COMBINED BUILDING RISK SCORING FUNCTIONS\n",
    "# ============================================\n",
    "# Note: RISK_WEIGHTS and RISK_THRESHOLDS are defined in the \n",
    "# Risk Scoring Configuration cell above\n",
    "\n",
    "def calculate_building_risk(building_geom, soil_handler, tree_data):\n",
    "    \"\"\"\n",
    "    Calculate combined subsidence risk score for a building.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    building_geom : shapely.geometry\n",
    "        Building polygon geometry\n",
    "    soil_handler : SoilRasterHandler\n",
    "        Soil raster data handler\n",
    "    tree_data : GeoDataFrame\n",
    "        Tree dataset\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Complete risk assessment for the building\n",
    "    \"\"\"\n",
    "    # Get soil risk\n",
    "    soil_result = get_building_soil_score(building_geom, soil_handler)\n",
    "    \n",
    "    # Get tree risk\n",
    "    tree_result = get_building_tree_score(building_geom, tree_data)\n",
    "    \n",
    "    # Calculate combined score (weighted average)\n",
    "    combined_score = (\n",
    "        soil_result['soil_score'] * RISK_WEIGHTS['soil'] +\n",
    "        tree_result['tree_score'] * RISK_WEIGHTS['tree']\n",
    "    )\n",
    "    \n",
    "    # Determine risk category using thresholds from config\n",
    "    if combined_score >= RISK_THRESHOLDS['high']:\n",
    "        risk_category = 'High'\n",
    "    elif combined_score >= RISK_THRESHOLDS['medium']:\n",
    "        risk_category = 'Medium'\n",
    "    else:\n",
    "        risk_category = 'Low'\n",
    "    \n",
    "    return {\n",
    "        'combined_score': combined_score,\n",
    "        'risk_category': risk_category,\n",
    "        'soil_score': soil_result['soil_score'],\n",
    "        'soil_type': soil_result['soil_type'],\n",
    "        'tree_score': tree_result['tree_score'],\n",
    "        'nearby_trees': tree_result['nearby_trees'],\n",
    "        'trees_in_root_zone': tree_result['trees_in_root_zone'],\n",
    "        'closest_tree_m': tree_result['closest_tree_m'],\n",
    "        'top_tree_contributors': tree_result['tree_details'][:3] if tree_result['tree_details'] else []\n",
    "    }\n",
    "\n",
    "def score_all_buildings(building_data, soil_handler, tree_data, progress_interval=50):\n",
    "    \"\"\"\n",
    "    Calculate risk scores for all buildings.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    building_data : GeoDataFrame\n",
    "        Building footprints\n",
    "    soil_handler : SoilRasterHandler\n",
    "        Soil raster data handler\n",
    "    tree_data : GeoDataFrame\n",
    "        Tree dataset\n",
    "    progress_interval : int\n",
    "        Print progress every N buildings\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    GeoDataFrame\n",
    "        Buildings with risk scores added\n",
    "    \"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"CALCULATING BUILDING RISK SCORES\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"\\nProcessing {len(building_data)} buildings...\")\n",
    "    print(f\"Risk weights: Soil={RISK_WEIGHTS['soil']:.0%}, Trees={RISK_WEIGHTS['tree']:.0%}\")\n",
    "    print(f\"Risk thresholds: High‚â•{RISK_THRESHOLDS['high']}, Medium‚â•{RISK_THRESHOLDS['medium']}\")\n",
    "    \n",
    "    # Prepare results columns\n",
    "    results = []\n",
    "    \n",
    "    for idx, (i, building) in enumerate(building_data.iterrows()):\n",
    "        if idx > 0 and idx % progress_interval == 0:\n",
    "            print(f\"  Processed {idx}/{len(building_data)} buildings...\")\n",
    "        \n",
    "        # Calculate risk for this building\n",
    "        risk = calculate_building_risk(building.geometry, soil_handler, tree_data)\n",
    "        results.append(risk)\n",
    "    \n",
    "    # Add results to building data\n",
    "    scored_buildings = building_data.copy()\n",
    "    \n",
    "    scored_buildings['risk_score'] = [r['combined_score'] for r in results]\n",
    "    scored_buildings['risk_category'] = [r['risk_category'] for r in results]\n",
    "    scored_buildings['soil_score'] = [r['soil_score'] for r in results]\n",
    "    scored_buildings['soil_type'] = [r['soil_type'] for r in results]\n",
    "    scored_buildings['tree_score'] = [r['tree_score'] for r in results]\n",
    "    scored_buildings['nearby_trees'] = [r['nearby_trees'] for r in results]\n",
    "    scored_buildings['trees_in_root_zone'] = [r['trees_in_root_zone'] for r in results]\n",
    "    scored_buildings['closest_tree_m'] = [r['closest_tree_m'] for r in results]\n",
    "    \n",
    "    print(f\"\\n‚úì Completed scoring for {len(scored_buildings)} buildings\")\n",
    "    \n",
    "    # Summary statistics\n",
    "    print(f\"\\n{'=' * 60}\")\n",
    "    print(\"RISK SUMMARY\")\n",
    "    print(f\"{'=' * 60}\")\n",
    "    \n",
    "    print(f\"\\nRisk Category Distribution:\")\n",
    "    for cat in ['High', 'Medium', 'Low']:\n",
    "        count = len(scored_buildings[scored_buildings['risk_category'] == cat])\n",
    "        pct = count / len(scored_buildings) * 100\n",
    "        print(f\"  {cat:8s}: {count:4d} buildings ({pct:5.1f}%)\")\n",
    "    \n",
    "    print(f\"\\nScore Statistics:\")\n",
    "    print(f\"  Combined: mean={scored_buildings['risk_score'].mean():.2f}, \"\n",
    "          f\"min={scored_buildings['risk_score'].min():.2f}, \"\n",
    "          f\"max={scored_buildings['risk_score'].max():.2f}\")\n",
    "    print(f\"  Soil:     mean={scored_buildings['soil_score'].mean():.2f}, \"\n",
    "          f\"min={scored_buildings['soil_score'].min():.2f}, \"\n",
    "          f\"max={scored_buildings['soil_score'].max():.2f}\")\n",
    "    print(f\"  Tree:     mean={scored_buildings['tree_score'].mean():.2f}, \"\n",
    "          f\"min={scored_buildings['tree_score'].min():.2f}, \"\n",
    "          f\"max={scored_buildings['tree_score'].max():.2f}\")\n",
    "    \n",
    "    print(f\"\\nSoil Type Distribution:\")\n",
    "    print(scored_buildings['soil_type'].value_counts())\n",
    "    \n",
    "    return scored_buildings\n",
    "\n",
    "print(\"‚úì Combined risk scoring functions loaded (using config from above)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "fa467a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìç Filtering buildings to soil raster bounds:\n",
      "   Original: 227,578 buildings\n",
      "   Within bounds: 227,361 buildings\n",
      "   Removed: 217 buildings (0.1%)\n",
      "============================================================\n",
      "CALCULATING BUILDING RISK SCORES\n",
      "============================================================\n",
      "\n",
      "Processing 227361 buildings...\n",
      "Risk weights: Soil=40%, Trees=60%\n",
      "Risk thresholds: High‚â•7.0, Medium‚â•4.0\n",
      "  Processed 1000/227361 buildings...\n",
      "  Processed 2000/227361 buildings...\n",
      "  Processed 2000/227361 buildings...\n",
      "  Processed 3000/227361 buildings...\n",
      "  Processed 3000/227361 buildings...\n",
      "  Processed 4000/227361 buildings...\n",
      "  Processed 4000/227361 buildings...\n",
      "  Processed 5000/227361 buildings...\n",
      "  Processed 5000/227361 buildings...\n",
      "  Processed 6000/227361 buildings...\n",
      "  Processed 6000/227361 buildings...\n",
      "  Processed 7000/227361 buildings...\n",
      "  Processed 7000/227361 buildings...\n",
      "  Processed 8000/227361 buildings...\n",
      "  Processed 8000/227361 buildings...\n",
      "  Processed 9000/227361 buildings...\n",
      "  Processed 9000/227361 buildings...\n",
      "  Processed 10000/227361 buildings...\n",
      "  Processed 10000/227361 buildings...\n",
      "  Processed 11000/227361 buildings...\n",
      "  Processed 11000/227361 buildings...\n",
      "  Processed 12000/227361 buildings...\n",
      "  Processed 13000/227361 buildings...\n",
      "  Processed 12000/227361 buildings...\n",
      "  Processed 13000/227361 buildings...\n",
      "  Processed 14000/227361 buildings...\n",
      "  Processed 14000/227361 buildings...\n",
      "  Processed 15000/227361 buildings...\n",
      "  Processed 16000/227361 buildings...\n",
      "  Processed 15000/227361 buildings...\n",
      "  Processed 16000/227361 buildings...\n",
      "  Processed 17000/227361 buildings...\n",
      "  Processed 18000/227361 buildings...\n",
      "  Processed 17000/227361 buildings...\n",
      "  Processed 18000/227361 buildings...\n",
      "  Processed 19000/227361 buildings...\n",
      "  Processed 19000/227361 buildings...\n",
      "  Processed 20000/227361 buildings...\n",
      "  Processed 20000/227361 buildings...\n",
      "  Processed 21000/227361 buildings...\n",
      "  Processed 21000/227361 buildings...\n",
      "  Processed 22000/227361 buildings...\n",
      "  Processed 22000/227361 buildings...\n",
      "  Processed 23000/227361 buildings...\n",
      "  Processed 24000/227361 buildings...\n",
      "  Processed 23000/227361 buildings...\n",
      "  Processed 24000/227361 buildings...\n",
      "  Processed 25000/227361 buildings...\n",
      "  Processed 25000/227361 buildings...\n",
      "  Processed 26000/227361 buildings...\n",
      "  Processed 27000/227361 buildings...\n",
      "  Processed 26000/227361 buildings...\n",
      "  Processed 27000/227361 buildings...\n",
      "  Processed 28000/227361 buildings...\n",
      "  Processed 28000/227361 buildings...\n",
      "  Processed 29000/227361 buildings...\n",
      "  Processed 29000/227361 buildings...\n",
      "  Processed 30000/227361 buildings...\n",
      "  Processed 30000/227361 buildings...\n",
      "  Processed 31000/227361 buildings...\n",
      "  Processed 31000/227361 buildings...\n",
      "  Processed 32000/227361 buildings...\n",
      "  Processed 32000/227361 buildings...\n",
      "  Processed 33000/227361 buildings...\n",
      "  Processed 33000/227361 buildings...\n",
      "  Processed 34000/227361 buildings...\n",
      "  Processed 35000/227361 buildings...\n",
      "  Processed 34000/227361 buildings...\n",
      "  Processed 35000/227361 buildings...\n",
      "  Processed 36000/227361 buildings...\n",
      "  Processed 36000/227361 buildings...\n",
      "  Processed 37000/227361 buildings...\n",
      "  Processed 37000/227361 buildings...\n",
      "  Processed 38000/227361 buildings...\n",
      "  Processed 38000/227361 buildings...\n",
      "  Processed 39000/227361 buildings...\n",
      "  Processed 39000/227361 buildings...\n",
      "  Processed 40000/227361 buildings...\n",
      "  Processed 40000/227361 buildings...\n",
      "  Processed 41000/227361 buildings...\n",
      "  Processed 42000/227361 buildings...\n",
      "  Processed 41000/227361 buildings...\n",
      "  Processed 42000/227361 buildings...\n",
      "  Processed 43000/227361 buildings...\n",
      "  Processed 44000/227361 buildings...\n",
      "  Processed 43000/227361 buildings...\n",
      "  Processed 44000/227361 buildings...\n",
      "  Processed 45000/227361 buildings...\n",
      "  Processed 46000/227361 buildings...\n",
      "  Processed 45000/227361 buildings...\n",
      "  Processed 46000/227361 buildings...\n",
      "  Processed 47000/227361 buildings...\n",
      "  Processed 47000/227361 buildings...\n",
      "  Processed 48000/227361 buildings...\n",
      "  Processed 49000/227361 buildings...\n",
      "  Processed 48000/227361 buildings...\n",
      "  Processed 49000/227361 buildings...\n",
      "  Processed 50000/227361 buildings...\n",
      "  Processed 50000/227361 buildings...\n",
      "  Processed 51000/227361 buildings...\n",
      "  Processed 51000/227361 buildings...\n",
      "  Processed 52000/227361 buildings...\n",
      "  Processed 52000/227361 buildings...\n",
      "  Processed 53000/227361 buildings...\n",
      "  Processed 53000/227361 buildings...\n",
      "  Processed 54000/227361 buildings...\n",
      "  Processed 54000/227361 buildings...\n",
      "  Processed 55000/227361 buildings...\n",
      "  Processed 55000/227361 buildings...\n",
      "  Processed 56000/227361 buildings...\n",
      "  Processed 56000/227361 buildings...\n",
      "  Processed 57000/227361 buildings...\n",
      "  Processed 57000/227361 buildings...\n",
      "  Processed 58000/227361 buildings...\n",
      "  Processed 59000/227361 buildings...\n",
      "  Processed 58000/227361 buildings...\n",
      "  Processed 59000/227361 buildings...\n",
      "  Processed 60000/227361 buildings...\n",
      "  Processed 61000/227361 buildings...\n",
      "  Processed 60000/227361 buildings...\n",
      "  Processed 61000/227361 buildings...\n",
      "  Processed 62000/227361 buildings...\n",
      "  Processed 62000/227361 buildings...\n",
      "  Processed 63000/227361 buildings...\n",
      "  Processed 64000/227361 buildings...\n",
      "  Processed 63000/227361 buildings...\n",
      "  Processed 64000/227361 buildings...\n",
      "  Processed 65000/227361 buildings...\n",
      "  Processed 65000/227361 buildings...\n",
      "  Processed 66000/227361 buildings...\n",
      "  Processed 66000/227361 buildings...\n",
      "  Processed 67000/227361 buildings...\n",
      "  Processed 68000/227361 buildings...\n",
      "  Processed 67000/227361 buildings...\n",
      "  Processed 68000/227361 buildings...\n",
      "  Processed 69000/227361 buildings...\n",
      "  Processed 70000/227361 buildings...\n",
      "  Processed 69000/227361 buildings...\n",
      "  Processed 70000/227361 buildings...\n",
      "  Processed 71000/227361 buildings...\n",
      "  Processed 72000/227361 buildings...\n",
      "  Processed 71000/227361 buildings...\n",
      "  Processed 72000/227361 buildings...\n",
      "  Processed 73000/227361 buildings...\n",
      "  Processed 74000/227361 buildings...\n",
      "  Processed 73000/227361 buildings...\n",
      "  Processed 74000/227361 buildings...\n",
      "  Processed 75000/227361 buildings...\n",
      "  Processed 75000/227361 buildings...\n",
      "  Processed 76000/227361 buildings...\n",
      "  Processed 77000/227361 buildings...\n",
      "  Processed 76000/227361 buildings...\n",
      "  Processed 77000/227361 buildings...\n",
      "  Processed 78000/227361 buildings...\n",
      "  Processed 78000/227361 buildings...\n",
      "  Processed 79000/227361 buildings...\n",
      "  Processed 80000/227361 buildings...\n",
      "  Processed 79000/227361 buildings...\n",
      "  Processed 80000/227361 buildings...\n",
      "  Processed 81000/227361 buildings...\n",
      "  Processed 81000/227361 buildings...\n",
      "  Processed 82000/227361 buildings...\n",
      "  Processed 83000/227361 buildings...\n",
      "  Processed 82000/227361 buildings...\n",
      "  Processed 83000/227361 buildings...\n",
      "  Processed 84000/227361 buildings...\n",
      "  Processed 85000/227361 buildings...\n",
      "  Processed 84000/227361 buildings...\n",
      "  Processed 85000/227361 buildings...\n",
      "  Processed 86000/227361 buildings...\n",
      "  Processed 87000/227361 buildings...\n",
      "  Processed 86000/227361 buildings...\n",
      "  Processed 87000/227361 buildings...\n",
      "  Processed 88000/227361 buildings...\n",
      "  Processed 89000/227361 buildings...\n",
      "  Processed 88000/227361 buildings...\n",
      "  Processed 89000/227361 buildings...\n",
      "  Processed 90000/227361 buildings...\n",
      "  Processed 90000/227361 buildings...\n",
      "  Processed 91000/227361 buildings...\n",
      "  Processed 92000/227361 buildings...\n",
      "  Processed 91000/227361 buildings...\n",
      "  Processed 92000/227361 buildings...\n",
      "  Processed 93000/227361 buildings...\n",
      "  Processed 93000/227361 buildings...\n",
      "  Processed 94000/227361 buildings...\n",
      "  Processed 94000/227361 buildings...\n",
      "  Processed 95000/227361 buildings...\n",
      "  Processed 96000/227361 buildings...\n",
      "  Processed 95000/227361 buildings...\n",
      "  Processed 96000/227361 buildings...\n",
      "  Processed 97000/227361 buildings...\n",
      "  Processed 97000/227361 buildings...\n",
      "  Processed 98000/227361 buildings...\n",
      "  Processed 98000/227361 buildings...\n",
      "  Processed 99000/227361 buildings...\n",
      "  Processed 100000/227361 buildings...\n",
      "  Processed 99000/227361 buildings...\n",
      "  Processed 100000/227361 buildings...\n",
      "  Processed 101000/227361 buildings...\n",
      "  Processed 101000/227361 buildings...\n",
      "  Processed 102000/227361 buildings...\n",
      "  Processed 102000/227361 buildings...\n",
      "  Processed 103000/227361 buildings...\n",
      "  Processed 104000/227361 buildings...\n",
      "  Processed 103000/227361 buildings...\n",
      "  Processed 104000/227361 buildings...\n",
      "  Processed 105000/227361 buildings...\n",
      "  Processed 106000/227361 buildings...\n",
      "  Processed 105000/227361 buildings...\n",
      "  Processed 106000/227361 buildings...\n",
      "  Processed 107000/227361 buildings...\n",
      "  Processed 108000/227361 buildings...\n",
      "  Processed 107000/227361 buildings...\n",
      "  Processed 108000/227361 buildings...\n",
      "  Processed 109000/227361 buildings...\n",
      "  Processed 110000/227361 buildings...\n",
      "  Processed 109000/227361 buildings...\n",
      "  Processed 110000/227361 buildings...\n",
      "  Processed 111000/227361 buildings...\n",
      "  Processed 112000/227361 buildings...\n",
      "  Processed 111000/227361 buildings...\n",
      "  Processed 112000/227361 buildings...\n",
      "  Processed 113000/227361 buildings...\n",
      "  Processed 114000/227361 buildings...\n",
      "  Processed 113000/227361 buildings...\n",
      "  Processed 114000/227361 buildings...\n",
      "  Processed 115000/227361 buildings...\n",
      "  Processed 116000/227361 buildings...\n",
      "  Processed 115000/227361 buildings...\n",
      "  Processed 116000/227361 buildings...\n",
      "  Processed 117000/227361 buildings...\n",
      "  Processed 118000/227361 buildings...\n",
      "  Processed 117000/227361 buildings...\n",
      "  Processed 118000/227361 buildings...\n",
      "  Processed 119000/227361 buildings...\n",
      "  Processed 120000/227361 buildings...\n",
      "  Processed 119000/227361 buildings...\n",
      "  Processed 120000/227361 buildings...\n",
      "  Processed 121000/227361 buildings...\n",
      "  Processed 122000/227361 buildings...\n",
      "  Processed 121000/227361 buildings...\n",
      "  Processed 122000/227361 buildings...\n",
      "  Processed 123000/227361 buildings...\n",
      "  Processed 124000/227361 buildings...\n",
      "  Processed 123000/227361 buildings...\n",
      "  Processed 124000/227361 buildings...\n",
      "  Processed 125000/227361 buildings...\n",
      "  Processed 125000/227361 buildings...\n",
      "  Processed 126000/227361 buildings...\n",
      "  Processed 127000/227361 buildings...\n",
      "  Processed 126000/227361 buildings...\n",
      "  Processed 127000/227361 buildings...\n",
      "  Processed 128000/227361 buildings...\n",
      "  Processed 129000/227361 buildings...\n",
      "  Processed 128000/227361 buildings...\n",
      "  Processed 129000/227361 buildings...\n",
      "  Processed 130000/227361 buildings...\n",
      "  Processed 131000/227361 buildings...\n",
      "  Processed 130000/227361 buildings...\n",
      "  Processed 131000/227361 buildings...\n",
      "  Processed 132000/227361 buildings...\n",
      "  Processed 133000/227361 buildings...\n",
      "  Processed 132000/227361 buildings...\n",
      "  Processed 133000/227361 buildings...\n",
      "  Processed 134000/227361 buildings...\n",
      "  Processed 135000/227361 buildings...\n",
      "  Processed 136000/227361 buildings...\n",
      "  Processed 134000/227361 buildings...\n",
      "  Processed 135000/227361 buildings...\n",
      "  Processed 136000/227361 buildings...\n",
      "  Processed 137000/227361 buildings...\n",
      "  Processed 137000/227361 buildings...\n",
      "  Processed 138000/227361 buildings...\n",
      "  Processed 139000/227361 buildings...\n",
      "  Processed 138000/227361 buildings...\n",
      "  Processed 139000/227361 buildings...\n",
      "  Processed 140000/227361 buildings...\n",
      "  Processed 141000/227361 buildings...\n",
      "  Processed 140000/227361 buildings...\n",
      "  Processed 141000/227361 buildings...\n",
      "  Processed 142000/227361 buildings...\n",
      "  Processed 143000/227361 buildings...\n",
      "  Processed 142000/227361 buildings...\n",
      "  Processed 143000/227361 buildings...\n",
      "  Processed 144000/227361 buildings...\n",
      "  Processed 145000/227361 buildings...\n",
      "  Processed 144000/227361 buildings...\n",
      "  Processed 145000/227361 buildings...\n",
      "  Processed 146000/227361 buildings...\n",
      "  Processed 147000/227361 buildings...\n",
      "  Processed 146000/227361 buildings...\n",
      "  Processed 147000/227361 buildings...\n",
      "  Processed 148000/227361 buildings...\n",
      "  Processed 149000/227361 buildings...\n",
      "  Processed 148000/227361 buildings...\n",
      "  Processed 149000/227361 buildings...\n",
      "  Processed 150000/227361 buildings...\n",
      "  Processed 151000/227361 buildings...\n",
      "  Processed 150000/227361 buildings...\n",
      "  Processed 151000/227361 buildings...\n",
      "  Processed 152000/227361 buildings...\n",
      "  Processed 153000/227361 buildings...\n",
      "  Processed 152000/227361 buildings...\n",
      "  Processed 153000/227361 buildings...\n",
      "  Processed 154000/227361 buildings...\n",
      "  Processed 155000/227361 buildings...\n",
      "  Processed 154000/227361 buildings...\n",
      "  Processed 155000/227361 buildings...\n",
      "  Processed 156000/227361 buildings...\n",
      "  Processed 157000/227361 buildings...\n",
      "  Processed 156000/227361 buildings...\n",
      "  Processed 157000/227361 buildings...\n",
      "  Processed 158000/227361 buildings...\n",
      "  Processed 158000/227361 buildings...\n",
      "  Processed 159000/227361 buildings...\n",
      "  Processed 159000/227361 buildings...\n",
      "  Processed 160000/227361 buildings...\n",
      "  Processed 161000/227361 buildings...\n",
      "  Processed 160000/227361 buildings...\n",
      "  Processed 161000/227361 buildings...\n",
      "  Processed 162000/227361 buildings...\n",
      "  Processed 162000/227361 buildings...\n",
      "  Processed 163000/227361 buildings...\n",
      "  Processed 163000/227361 buildings...\n",
      "  Processed 164000/227361 buildings...\n",
      "  Processed 165000/227361 buildings...\n",
      "  Processed 164000/227361 buildings...\n",
      "  Processed 165000/227361 buildings...\n",
      "  Processed 166000/227361 buildings...\n",
      "  Processed 167000/227361 buildings...\n",
      "  Processed 166000/227361 buildings...\n",
      "  Processed 167000/227361 buildings...\n",
      "  Processed 168000/227361 buildings...\n",
      "  Processed 169000/227361 buildings...\n",
      "  Processed 168000/227361 buildings...\n",
      "  Processed 169000/227361 buildings...\n",
      "  Processed 170000/227361 buildings...\n",
      "  Processed 171000/227361 buildings...\n",
      "  Processed 170000/227361 buildings...\n",
      "  Processed 171000/227361 buildings...\n",
      "  Processed 172000/227361 buildings...\n",
      "  Processed 173000/227361 buildings...\n",
      "  Processed 172000/227361 buildings...\n",
      "  Processed 173000/227361 buildings...\n",
      "  Processed 174000/227361 buildings...\n",
      "  Processed 175000/227361 buildings...\n",
      "  Processed 174000/227361 buildings...\n",
      "  Processed 175000/227361 buildings...\n",
      "  Processed 176000/227361 buildings...\n",
      "  Processed 177000/227361 buildings...\n",
      "  Processed 176000/227361 buildings...\n",
      "  Processed 177000/227361 buildings...\n",
      "  Processed 178000/227361 buildings...\n",
      "  Processed 179000/227361 buildings...\n",
      "  Processed 178000/227361 buildings...\n",
      "  Processed 179000/227361 buildings...\n",
      "  Processed 180000/227361 buildings...\n",
      "  Processed 180000/227361 buildings...\n",
      "  Processed 181000/227361 buildings...\n",
      "  Processed 182000/227361 buildings...\n",
      "  Processed 181000/227361 buildings...\n",
      "  Processed 182000/227361 buildings...\n",
      "  Processed 183000/227361 buildings...\n",
      "  Processed 184000/227361 buildings...\n",
      "  Processed 183000/227361 buildings...\n",
      "  Processed 184000/227361 buildings...\n",
      "  Processed 185000/227361 buildings...\n",
      "  Processed 186000/227361 buildings...\n",
      "  Processed 185000/227361 buildings...\n",
      "  Processed 186000/227361 buildings...\n",
      "  Processed 187000/227361 buildings...\n",
      "  Processed 188000/227361 buildings...\n",
      "  Processed 187000/227361 buildings...\n",
      "  Processed 188000/227361 buildings...\n",
      "  Processed 189000/227361 buildings...\n",
      "  Processed 189000/227361 buildings...\n",
      "  Processed 190000/227361 buildings...\n",
      "  Processed 191000/227361 buildings...\n",
      "  Processed 190000/227361 buildings...\n",
      "  Processed 191000/227361 buildings...\n",
      "  Processed 192000/227361 buildings...\n",
      "  Processed 193000/227361 buildings...\n",
      "  Processed 192000/227361 buildings...\n",
      "  Processed 193000/227361 buildings...\n",
      "  Processed 194000/227361 buildings...\n",
      "  Processed 195000/227361 buildings...\n",
      "  Processed 196000/227361 buildings...\n",
      "  Processed 194000/227361 buildings...\n",
      "  Processed 195000/227361 buildings...\n",
      "  Processed 196000/227361 buildings...\n",
      "  Processed 197000/227361 buildings...\n",
      "  Processed 197000/227361 buildings...\n",
      "  Processed 198000/227361 buildings...\n",
      "  Processed 198000/227361 buildings...\n",
      "  Processed 199000/227361 buildings...\n",
      "  Processed 200000/227361 buildings...\n",
      "  Processed 199000/227361 buildings...\n",
      "  Processed 200000/227361 buildings...\n",
      "  Processed 201000/227361 buildings...\n",
      "  Processed 202000/227361 buildings...\n",
      "  Processed 201000/227361 buildings...\n",
      "  Processed 202000/227361 buildings...\n",
      "  Processed 203000/227361 buildings...\n",
      "  Processed 203000/227361 buildings...\n",
      "  Processed 204000/227361 buildings...\n",
      "  Processed 205000/227361 buildings...\n",
      "  Processed 204000/227361 buildings...\n",
      "  Processed 205000/227361 buildings...\n",
      "  Processed 206000/227361 buildings...\n",
      "  Processed 207000/227361 buildings...\n",
      "  Processed 206000/227361 buildings...\n",
      "  Processed 207000/227361 buildings...\n",
      "  Processed 208000/227361 buildings...\n",
      "  Processed 209000/227361 buildings...\n",
      "  Processed 208000/227361 buildings...\n",
      "  Processed 209000/227361 buildings...\n",
      "  Processed 210000/227361 buildings...\n",
      "  Processed 210000/227361 buildings...\n",
      "  Processed 211000/227361 buildings...\n",
      "  Processed 211000/227361 buildings...\n",
      "  Processed 212000/227361 buildings...\n",
      "  Processed 213000/227361 buildings...\n",
      "  Processed 212000/227361 buildings...\n",
      "  Processed 213000/227361 buildings...\n",
      "  Processed 214000/227361 buildings...\n",
      "  Processed 214000/227361 buildings...\n",
      "  Processed 215000/227361 buildings...\n",
      "  Processed 215000/227361 buildings...\n",
      "  Processed 216000/227361 buildings...\n",
      "  Processed 216000/227361 buildings...\n",
      "  Processed 217000/227361 buildings...\n",
      "  Processed 218000/227361 buildings...\n",
      "  Processed 217000/227361 buildings...\n",
      "  Processed 218000/227361 buildings...\n",
      "  Processed 219000/227361 buildings...\n",
      "  Processed 219000/227361 buildings...\n",
      "  Processed 220000/227361 buildings...\n",
      "  Processed 220000/227361 buildings...\n",
      "  Processed 221000/227361 buildings...\n",
      "  Processed 221000/227361 buildings...\n",
      "  Processed 222000/227361 buildings...\n",
      "  Processed 223000/227361 buildings...\n",
      "  Processed 222000/227361 buildings...\n",
      "  Processed 223000/227361 buildings...\n",
      "  Processed 224000/227361 buildings...\n",
      "  Processed 225000/227361 buildings...\n",
      "  Processed 224000/227361 buildings...\n",
      "  Processed 225000/227361 buildings...\n",
      "  Processed 226000/227361 buildings...\n",
      "  Processed 226000/227361 buildings...\n",
      "  Processed 227000/227361 buildings...\n",
      "  Processed 227000/227361 buildings...\n",
      "\n",
      "‚úì Completed scoring for 227361 buildings\n",
      "\n",
      "============================================================\n",
      "RISK SUMMARY\n",
      "============================================================\n",
      "\n",
      "Risk Category Distribution:\n",
      "  High    :    0 buildings (  0.0%)\n",
      "  Medium  :  968 buildings (  0.4%)\n",
      "  Low     : 226393 buildings ( 99.6%)\n",
      "\n",
      "Score Statistics:\n",
      "  Combined: mean=0.76, min=0.00, max=6.80\n",
      "  Soil:     mean=1.53, min=0.00, max=4.00\n",
      "  Tree:     mean=0.25, min=0.00, max=10.00\n",
      "\n",
      "Soil Type Distribution:\n",
      "soil_type\n",
      "Sandy Loam    126823\n",
      "Sand           94398\n",
      "Unknown         5922\n",
      "Loam             218\n",
      "Name: count, dtype: int64\n",
      "\n",
      "‚úì Completed scoring for 227361 buildings\n",
      "\n",
      "============================================================\n",
      "RISK SUMMARY\n",
      "============================================================\n",
      "\n",
      "Risk Category Distribution:\n",
      "  High    :    0 buildings (  0.0%)\n",
      "  Medium  :  968 buildings (  0.4%)\n",
      "  Low     : 226393 buildings ( 99.6%)\n",
      "\n",
      "Score Statistics:\n",
      "  Combined: mean=0.76, min=0.00, max=6.80\n",
      "  Soil:     mean=1.53, min=0.00, max=4.00\n",
      "  Tree:     mean=0.25, min=0.00, max=10.00\n",
      "\n",
      "Soil Type Distribution:\n",
      "soil_type\n",
      "Sandy Loam    126823\n",
      "Sand           94398\n",
      "Unknown         5922\n",
      "Loam             218\n",
      "Name: count, dtype: int64\n",
      "\n",
      "‚úì Saved scored buildings to: bristol_buildings_scored.geojson\n",
      "\n",
      "‚úì Saved scored buildings to: bristol_buildings_scored.geojson\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# RUN BUILDING RISK ANALYSIS\n",
    "# ============================================\n",
    "\n",
    "# Load building data if not already loaded\n",
    "if 'building_data' not in dir() or building_data.empty:\n",
    "    try:\n",
    "        building_data = gpd.read_file('bristol_buildings_tiny.geojson')\n",
    "        print(f\"Loaded {len(building_data)} buildings from file\")\n",
    "    except:\n",
    "        print(\"‚ùå Building data not found. Run the building collection cell first.\")\n",
    "        building_data = gpd.GeoDataFrame()\n",
    "\n",
    "# Load tree data if not already loaded\n",
    "if 'tree_data' not in dir() or tree_data.empty:\n",
    "    print(\"‚ö†Ô∏è Tree data not loaded. Run the tree collection cell first for full analysis.\")\n",
    "    tree_data = gpd.GeoDataFrame()\n",
    "\n",
    "# Filter buildings to be within soil raster bounds\n",
    "if not building_data.empty and 'soil_handler' in dir():\n",
    "    original_count = len(building_data)\n",
    "    \n",
    "    # Get soil bounds\n",
    "    soil_bounds = soil_handler.bounds\n",
    "    \n",
    "    # Filter buildings whose centroid is within soil bounds\n",
    "    building_centroids = building_data.geometry.centroid\n",
    "    within_bounds_mask = (\n",
    "        (building_centroids.x >= soil_bounds['west']) &\n",
    "        (building_centroids.x <= soil_bounds['east']) &\n",
    "        (building_centroids.y >= soil_bounds['south']) &\n",
    "        (building_centroids.y <= soil_bounds['north'])\n",
    "    )\n",
    "    \n",
    "    building_data_filtered = building_data[within_bounds_mask].copy()\n",
    "    \n",
    "    filtered_count = len(building_data_filtered)\n",
    "    removed_count = original_count - filtered_count\n",
    "    \n",
    "    print(f\"üìç Filtering buildings to soil raster bounds:\")\n",
    "    print(f\"   Original: {original_count:,} buildings\")\n",
    "    print(f\"   Within bounds: {filtered_count:,} buildings\")\n",
    "    print(f\"   Removed: {removed_count:,} buildings ({removed_count/original_count*100:.1f}%)\")\n",
    "    \n",
    "    # Use filtered buildings for scoring\n",
    "    buildings_to_score = building_data_filtered\n",
    "else:\n",
    "    buildings_to_score = building_data\n",
    "\n",
    "# Score all buildings\n",
    "if not buildings_to_score.empty:\n",
    "    scored_buildings = score_all_buildings(\n",
    "        buildings_to_score, \n",
    "        soil_handler, \n",
    "        tree_data,\n",
    "        progress_interval=1000\n",
    "    )\n",
    "    \n",
    "    # Save scored buildings\n",
    "    scored_buildings.to_file('bristol_buildings_scored.geojson', driver='GeoJSON')\n",
    "    print(f\"\\n‚úì Saved scored buildings to: bristol_buildings_scored.geojson\")\n",
    "else:\n",
    "    print(\"‚ùå No building data available for scoring\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b38e2c",
   "metadata": {},
   "source": [
    "## 6. Visualization & Export\n",
    "\n",
    "### 6.1 Interactive Multi-Layer Map\n",
    "\n",
    "Creates an interactive Folium map with toggleable layers:\n",
    "- **üåç Soil Raster** - BGS soil texture overlay with transparency\n",
    "- **üî¥ High Risk Buildings** - Score ‚â• 7.0 (red)\n",
    "- **üü° Medium Risk Buildings** - Score 4.0-7.0 (orange)\n",
    "- **üü¢ Low Risk Buildings** - Score < 4.0 (green)\n",
    "- **üå≥ Trees** - With crown width and species info (off by default)\n",
    "\n",
    "**Note:** For performance, only the top N highest-risk buildings are displayed (configurable via `MAX_BUILDINGS_DISPLAY`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "4422673a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating multi-layer risk map...\n",
      "  ‚ö†Ô∏è 227,361 buildings in soil area - displaying top 10,000 highest risk\n",
      "  Adding soil raster layer...\n",
      "  Adding 10,000 building layers...\n",
      "  ‚ö†Ô∏è 227,361 buildings in soil area - displaying top 10,000 highest risk\n",
      "  Adding soil raster layer...\n",
      "  Adding 10,000 building layers...\n",
      "  Adding tree layer (55,235 trees in soil area)...\n",
      "    (Showing 2,000 of 55,235 trees)\n",
      "  Adding tree layer (55,235 trees in soil area)...\n",
      "    (Showing 2,000 of 55,235 trees)\n",
      "‚úì Map created successfully\n",
      "‚úì Map created successfully\n",
      "\n",
      "‚úì Map saved to: subsidence_risk_buildings.html\n",
      "\n",
      "‚úì Map saved to: subsidence_risk_buildings.html\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# MULTI-LAYER INTERACTIVE MAP\n",
    "# ============================================\n",
    "\n",
    "import base64\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "\n",
    "# Configuration for map display\n",
    "MAX_BUILDINGS_DISPLAY = 10000  # Limit buildings to prevent browser crashes\n",
    "\n",
    "def create_risk_map(scored_buildings, tree_data, soil_handler, max_buildings=MAX_BUILDINGS_DISPLAY, show_all_trees=True):\n",
    "    \"\"\"\n",
    "    Create interactive map with toggleable layers.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    scored_buildings : GeoDataFrame\n",
    "        Buildings with risk scores\n",
    "    tree_data : GeoDataFrame\n",
    "        Tree dataset\n",
    "    soil_handler : SoilRasterHandler\n",
    "        Soil raster data\n",
    "    max_buildings : int\n",
    "        Maximum number of buildings to display (shows highest risk first)\n",
    "    show_all_trees : bool\n",
    "        If False, only show trees within influence distance of buildings\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    folium.Map\n",
    "        Interactive map with all layers\n",
    "    \"\"\"\n",
    "    print(\"Creating multi-layer risk map...\")\n",
    "    \n",
    "    # FIRST: Filter buildings to only those within soil bounds\n",
    "    soil_bounds = soil_handler.bounds\n",
    "    building_centroids = scored_buildings.geometry.centroid\n",
    "    within_soil_mask = (\n",
    "        (building_centroids.x >= soil_bounds['west']) &\n",
    "        (building_centroids.x <= soil_bounds['east']) &\n",
    "        (building_centroids.y >= soil_bounds['south']) &\n",
    "        (building_centroids.y <= soil_bounds['north'])\n",
    "    )\n",
    "    \n",
    "    buildings_in_soil_area = scored_buildings[within_soil_mask].copy()\n",
    "    filtered_bounds = len(scored_buildings) - len(buildings_in_soil_area)\n",
    "    \n",
    "    if filtered_bounds > 0:\n",
    "        print(f\"  üìç Filtered {filtered_bounds:,} buildings outside soil bounds\")\n",
    "    \n",
    "    # Note: Buildings with Unknown soil type have soil_score=0, so they won't\n",
    "    # appear in top N highest risk unless they have high tree proximity scores\n",
    "    \n",
    "    total_in_area = len(buildings_in_soil_area)\n",
    "    \n",
    "    # THEN: Filter to top N highest risk buildings\n",
    "    if total_in_area > max_buildings:\n",
    "        print(f\"  ‚ö†Ô∏è {total_in_area:,} buildings in soil area - displaying top {max_buildings:,} highest risk\")\n",
    "        buildings_to_show = buildings_in_soil_area.nlargest(max_buildings, 'risk_score').copy()\n",
    "    else:\n",
    "        buildings_to_show = buildings_in_soil_area.copy()\n",
    "        print(f\"  Displaying all {len(buildings_to_show):,} buildings\")\n",
    "    \n",
    "    # Get map center from soil bounds (ensures alignment)\n",
    "    center_lat = (soil_bounds['north'] + soil_bounds['south']) / 2\n",
    "    center_lon = (soil_bounds['east'] + soil_bounds['west']) / 2\n",
    "    \n",
    "    # Create base map\n",
    "    m = folium.Map(\n",
    "        location=[center_lat, center_lon],\n",
    "        zoom_start=13,\n",
    "        tiles='cartodbpositron',\n",
    "        control_scale=True\n",
    "    )\n",
    "    \n",
    "    # ==========================================\n",
    "    # LAYER 1: Soil Raster Overlay\n",
    "    # ==========================================\n",
    "    print(\"  Adding soil raster layer...\")\n",
    "    \n",
    "    bounds, soil_colored = soil_handler.get_raster_for_folium()\n",
    "    \n",
    "    if soil_colored is not None:\n",
    "        img = Image.fromarray(soil_colored)\n",
    "        buffer = BytesIO()\n",
    "        img.save(buffer, format='PNG')\n",
    "        img_str = base64.b64encode(buffer.getvalue()).decode()\n",
    "        \n",
    "        soil_layer = folium.FeatureGroup(name='üåç Soil Type Raster', show=True)\n",
    "        \n",
    "        folium.raster_layers.ImageOverlay(\n",
    "            image=f'data:image/png;base64,{img_str}',\n",
    "            bounds=bounds,\n",
    "            opacity=0.5,\n",
    "            name='Soil'\n",
    "        ).add_to(soil_layer)\n",
    "        \n",
    "        soil_layer.add_to(m)\n",
    "    \n",
    "    # ==========================================\n",
    "    # LAYER 2: Buildings by Risk Score\n",
    "    # ==========================================\n",
    "    print(f\"  Adding {len(buildings_to_show):,} building layers...\")\n",
    "    \n",
    "    def get_risk_color(score):\n",
    "        if score >= 7:\n",
    "            return '#e74c3c'  # Red - High risk\n",
    "        elif score >= 4:\n",
    "            return '#f39c12'  # Orange - Medium risk\n",
    "        else:\n",
    "            return '#27ae60'  # Green - Low risk\n",
    "    \n",
    "    def get_risk_fill_opacity(score):\n",
    "        return 0.4 + (score / 10) * 0.4\n",
    "    \n",
    "    high_risk_layer = folium.FeatureGroup(name='üî¥ High Risk Buildings', show=True)\n",
    "    medium_risk_layer = folium.FeatureGroup(name='üü° Medium Risk Buildings', show=True)\n",
    "    low_risk_layer = folium.FeatureGroup(name='üü¢ Low Risk Buildings', show=True)\n",
    "    \n",
    "    for idx, building in buildings_to_show.iterrows():\n",
    "        score = building.get('risk_score', 0)\n",
    "        category = building.get('risk_category', 'Unknown')\n",
    "        \n",
    "        closest_tree = building.get('closest_tree_m')\n",
    "        closest_tree_str = f\"{closest_tree:.1f}m\" if closest_tree is not None and not pd.isna(closest_tree) else \"N/A\"\n",
    "        \n",
    "        popup_html = f\"\"\"\n",
    "        <div style=\"width: 250px; font-family: Arial, sans-serif;\">\n",
    "            <h4 style=\"margin: 0 0 10px 0; color: {get_risk_color(score)};\">\n",
    "                {category} Risk\n",
    "            </h4>\n",
    "            <table style=\"width: 100%; font-size: 12px;\">\n",
    "                <tr><td><b>Combined Score:</b></td><td>{score:.2f}/10</td></tr>\n",
    "                <tr><td><b>Soil Score:</b></td><td>{building.get('soil_score', 0):.2f}/10</td></tr>\n",
    "                <tr><td><b>Tree Score:</b></td><td>{building.get('tree_score', 0):.2f}/10</td></tr>\n",
    "                <tr><td><b>Soil Type:</b></td><td>{building.get('soil_type', 'Unknown')}</td></tr>\n",
    "                <tr><td><b>Nearby Trees:</b></td><td>{building.get('nearby_trees', 0)}</td></tr>\n",
    "                <tr><td><b>Trees in Root Zone:</b></td><td>{building.get('trees_in_root_zone', 0)}</td></tr>\n",
    "                <tr><td><b>Closest Tree:</b></td><td>{closest_tree_str}</td></tr>\n",
    "            </table>\n",
    "            <p style=\"font-size: 10px; color: #666; margin-top: 10px;\">\n",
    "                Building: {building.get('building', 'Unknown type')}<br>\n",
    "                OSM ID: {building.get('osm_id', 'N/A')}\n",
    "            </p>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "        \n",
    "        style = {\n",
    "            'fillColor': get_risk_color(score),\n",
    "            'color': '#333',\n",
    "            'weight': 1,\n",
    "            'fillOpacity': get_risk_fill_opacity(score)\n",
    "        }\n",
    "        \n",
    "        feature = folium.GeoJson(\n",
    "            building.geometry.__geo_interface__,\n",
    "            style_function=lambda x, s=style: s,\n",
    "            popup=folium.Popup(popup_html, max_width=300),\n",
    "            tooltip=f\"Risk: {score:.1f}/10 ({category})\"\n",
    "        )\n",
    "        \n",
    "        if category == 'High':\n",
    "            feature.add_to(high_risk_layer)\n",
    "        elif category == 'Medium':\n",
    "            feature.add_to(medium_risk_layer)\n",
    "        else:\n",
    "            feature.add_to(low_risk_layer)\n",
    "    \n",
    "    low_risk_layer.add_to(m)\n",
    "    medium_risk_layer.add_to(m)\n",
    "    high_risk_layer.add_to(m)\n",
    "    \n",
    "    # ==========================================\n",
    "    # LAYER 3: Trees (near displayed buildings only)\n",
    "    # ==========================================\n",
    "    if tree_data is not None and not tree_data.empty:\n",
    "        # Filter trees to soil bounds\n",
    "        trees_in_area = tree_data[\n",
    "            (tree_data.geometry.x >= soil_bounds['west']) &\n",
    "            (tree_data.geometry.x <= soil_bounds['east']) &\n",
    "            (tree_data.geometry.y >= soil_bounds['south']) &\n",
    "            (tree_data.geometry.y <= soil_bounds['north'])\n",
    "        ]\n",
    "        \n",
    "        print(f\"  Adding tree layer ({len(trees_in_area):,} trees in soil area)...\")\n",
    "        \n",
    "        tree_layer = folium.FeatureGroup(name='üå≥ Trees', show=False)\n",
    "        \n",
    "        max_trees_display = 2000\n",
    "        if len(trees_in_area) > max_trees_display:\n",
    "            trees_to_show = trees_in_area.sample(max_trees_display)\n",
    "            print(f\"    (Showing {max_trees_display:,} of {len(trees_in_area):,} trees)\")\n",
    "        else:\n",
    "            trees_to_show = trees_in_area\n",
    "        \n",
    "        for idx, tree in trees_to_show.iterrows():\n",
    "            crown_width = tree.get('CROWN_WIDTH', 5)\n",
    "            try:\n",
    "                crown_width = float(crown_width) if crown_width is not None else 5\n",
    "            except (ValueError, TypeError):\n",
    "                crown_width = 5\n",
    "            if pd.isna(crown_width) or crown_width <= 0:\n",
    "                crown_width = 5\n",
    "            \n",
    "            species = tree.get('COMMON_NAME', 'Unknown')\n",
    "            if pd.isna(species):\n",
    "                species = tree.get('LATIN_NAME', 'Unknown')\n",
    "            \n",
    "            radius = max(3, min(12, crown_width / 2))\n",
    "            \n",
    "            tree_popup = f\"\"\"\n",
    "            <div style=\"width: 200px;\">\n",
    "                <b>{species}</b><br>\n",
    "                Crown Width: {crown_width:.1f}m<br>\n",
    "                Crown Area: {tree.get('CROWN_AREA', 'N/A')}<br>\n",
    "                DBH: {tree.get('DBH', 'N/A')}<br>\n",
    "                Height: {tree.get('CROWN_HEIGHT', 'N/A')}m\n",
    "            </div>\n",
    "            \"\"\"\n",
    "            \n",
    "            folium.CircleMarker(\n",
    "                location=[tree.geometry.y, tree.geometry.x],\n",
    "                radius=radius,\n",
    "                color='darkgreen',\n",
    "                fill=True,\n",
    "                fillColor='green',\n",
    "                fillOpacity=0.6,\n",
    "                weight=1,\n",
    "                popup=folium.Popup(tree_popup, max_width=250),\n",
    "                tooltip=f\"{species}\"\n",
    "            ).add_to(tree_layer)\n",
    "        \n",
    "        tree_layer.add_to(m)\n",
    "    \n",
    "    # ==========================================\n",
    "    # LAYER 4: Legend\n",
    "    # ==========================================\n",
    "    legend_html = f\"\"\"\n",
    "    <div style=\"position: fixed; \n",
    "                bottom: 50px; left: 50px; \n",
    "                width: 220px; \n",
    "                background-color: white; \n",
    "                border: 2px solid #333; \n",
    "                border-radius: 5px;\n",
    "                padding: 10px;\n",
    "                font-family: Arial, sans-serif;\n",
    "                font-size: 12px;\n",
    "                z-index: 9999;\">\n",
    "        <h4 style=\"margin: 0 0 10px 0;\">Subsidence Risk</h4>\n",
    "        <div style=\"margin: 5px 0;\">\n",
    "            <span style=\"background: #e74c3c; width: 20px; height: 12px; display: inline-block; margin-right: 5px;\"></span>\n",
    "            High (‚â•7)\n",
    "        </div>\n",
    "        <div style=\"margin: 5px 0;\">\n",
    "            <span style=\"background: #f39c12; width: 20px; height: 12px; display: inline-block; margin-right: 5px;\"></span>\n",
    "            Medium (4-7)\n",
    "        </div>\n",
    "        <div style=\"margin: 5px 0;\">\n",
    "            <span style=\"background: #27ae60; width: 20px; height: 12px; display: inline-block; margin-right: 5px;\"></span>\n",
    "            Low (<4)\n",
    "        </div>\n",
    "        <hr style=\"margin: 10px 0;\">\n",
    "        <h4 style=\"margin: 0 0 10px 0;\">Soil Types</h4>\n",
    "        <div style=\"margin: 5px 0;\">\n",
    "            <span style=\"background: rgb(100,60,40); width: 20px; height: 12px; display: inline-block; margin-right: 5px;\"></span>\n",
    "            Heavy Clay\n",
    "        </div>\n",
    "        <div style=\"margin: 5px 0;\">\n",
    "            <span style=\"background: rgb(180,150,100); width: 20px; height: 12px; display: inline-block; margin-right: 5px;\"></span>\n",
    "            Clay Loam\n",
    "        </div>\n",
    "        <div style=\"margin: 5px 0;\">\n",
    "            <span style=\"background: rgb(255,255,200); width: 20px; height: 12px; display: inline-block; margin-right: 5px;\"></span>\n",
    "            Sand\n",
    "        </div>\n",
    "        <hr style=\"margin: 10px 0;\">\n",
    "        <div style=\"font-size: 10px; color: #666;\">\n",
    "            Showing top {max_buildings:,} highest<br>\n",
    "            risk of {total_in_area:,} buildings<br>\n",
    "            within soil data area\n",
    "        </div>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    m.get_root().html.add_child(folium.Element(legend_html))\n",
    "    \n",
    "    # ==========================================\n",
    "    # Add Layer Control\n",
    "    # ==========================================\n",
    "    folium.LayerControl(collapsed=False).add_to(m)\n",
    "    \n",
    "    print(\"‚úì Map created successfully\")\n",
    "    \n",
    "    return m\n",
    "\n",
    "# Create the map\n",
    "if 'scored_buildings' in dir() and not scored_buildings.empty:\n",
    "    risk_map = create_risk_map(\n",
    "        scored_buildings,\n",
    "        tree_data if 'tree_data' in dir() else gpd.GeoDataFrame(),\n",
    "        soil_handler,\n",
    "        max_buildings=MAX_BUILDINGS_DISPLAY\n",
    "    )\n",
    "    \n",
    "    # Save map\n",
    "    risk_map.save('subsidence_risk_buildings.html')\n",
    "    print(f\"\\n‚úì Map saved to: subsidence_risk_buildings.html\")\n",
    "    \n",
    "    # Display in notebook\n",
    "    risk_map\n",
    "else:\n",
    "    print(\"‚ùå Run the building scoring cell first to create scored_buildings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "157a78b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TOP 10 HIGHEST RISK BUILDINGS\n",
      "============================================================\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "#1 - OSM ID: 23695879\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "  Risk Score:     3.00/10 (Low)\n",
      "  Soil Score:     5.00/10\n",
      "  Tree Score:     0.00/10\n",
      "  Soil Type:      Unknown\n",
      "  Building Type:  school\n",
      "  Nearby Trees:   0\n",
      "  In Root Zone:   0\n",
      "  Closest Tree:   nanm\n",
      "  Location:       (51.499139, -2.501894)\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "#2 - OSM ID: 23951773\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "  Risk Score:     3.00/10 (Low)\n",
      "  Soil Score:     5.00/10\n",
      "  Tree Score:     0.00/10\n",
      "  Soil Type:      Unknown\n",
      "  Building Type:  hangar\n",
      "  Nearby Trees:   0\n",
      "  In Root Zone:   0\n",
      "  Closest Tree:   nanm\n",
      "  Location:       (51.481431, -2.501232)\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "#3 - OSM ID: 42462950\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "  Risk Score:     3.00/10 (Low)\n",
      "  Soil Score:     5.00/10\n",
      "  Tree Score:     0.00/10\n",
      "  Soil Type:      Unknown\n",
      "  Building Type:  yes\n",
      "  Nearby Trees:   0\n",
      "  In Root Zone:   0\n",
      "  Closest Tree:   nanm\n",
      "  Location:       (51.448640, -2.500296)\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "#4 - OSM ID: 70976773\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "  Risk Score:     3.00/10 (Low)\n",
      "  Soil Score:     5.00/10\n",
      "  Tree Score:     0.00/10\n",
      "  Soil Type:      Unknown\n",
      "  Building Type:  yes\n",
      "  Nearby Trees:   0\n",
      "  In Root Zone:   0\n",
      "  Closest Tree:   nanm\n",
      "  Location:       (51.488802, -2.500070)\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "#5 - OSM ID: 71198557\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "  Risk Score:     3.00/10 (Low)\n",
      "  Soil Score:     5.00/10\n",
      "  Tree Score:     0.00/10\n",
      "  Soil Type:      Unknown\n",
      "  Building Type:  yes\n",
      "  Nearby Trees:   0\n",
      "  In Root Zone:   0\n",
      "  Closest Tree:   nanm\n",
      "  Location:       (51.481137, -2.502898)\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "#6 - OSM ID: 71263042\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "  Risk Score:     3.00/10 (Low)\n",
      "  Soil Score:     5.00/10\n",
      "  Tree Score:     0.00/10\n",
      "  Soil Type:      Unknown\n",
      "  Building Type:  yes\n",
      "  Nearby Trees:   0\n",
      "  In Root Zone:   0\n",
      "  Closest Tree:   nanm\n",
      "  Location:       (51.482044, -2.500954)\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "#7 - OSM ID: 88375918\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "  Risk Score:     3.00/10 (Low)\n",
      "  Soil Score:     5.00/10\n",
      "  Tree Score:     0.00/10\n",
      "  Soil Type:      Unknown\n",
      "  Building Type:  yes\n",
      "  Nearby Trees:   0\n",
      "  In Root Zone:   0\n",
      "  Closest Tree:   nanm\n",
      "  Location:       (51.481130, -2.502362)\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "#8 - OSM ID: 105179135\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "  Risk Score:     3.00/10 (Low)\n",
      "  Soil Score:     5.00/10\n",
      "  Tree Score:     0.00/10\n",
      "  Soil Type:      Unknown\n",
      "  Building Type:  supermarket\n",
      "  Nearby Trees:   0\n",
      "  In Root Zone:   0\n",
      "  Closest Tree:   nanm\n",
      "  Location:       (51.416531, -2.501566)\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "#9 - OSM ID: 106231210\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "  Risk Score:     3.00/10 (Low)\n",
      "  Soil Score:     5.00/10\n",
      "  Tree Score:     0.00/10\n",
      "  Soil Type:      Unknown\n",
      "  Building Type:  yes\n",
      "  Nearby Trees:   0\n",
      "  In Root Zone:   0\n",
      "  Closest Tree:   nanm\n",
      "  Location:       (51.462499, -2.500924)\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "#10 - OSM ID: 111184964\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "  Risk Score:     3.00/10 (Low)\n",
      "  Soil Score:     5.00/10\n",
      "  Tree Score:     0.00/10\n",
      "  Soil Type:      Unknown\n",
      "  Building Type:  warehouse\n",
      "  Nearby Trees:   0\n",
      "  In Root Zone:   0\n",
      "  Closest Tree:   nanm\n",
      "  Location:       (51.443713, -2.501376)\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# DETAILED BUILDING ANALYSIS\n",
    "# ============================================\n",
    "\n",
    "def analyze_high_risk_buildings(scored_buildings, top_n=10):\n",
    "    \"\"\"\n",
    "    Detailed analysis of highest risk buildings.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    scored_buildings : GeoDataFrame\n",
    "        Buildings with risk scores\n",
    "    top_n : int\n",
    "        Number of top buildings to analyze\n",
    "    \"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"TOP {top_n} HIGHEST RISK BUILDINGS\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Sort by risk score\n",
    "    high_risk = scored_buildings.nlargest(top_n, 'risk_score')\n",
    "    \n",
    "    for i, (idx, building) in enumerate(high_risk.iterrows(), 1):\n",
    "        print(f\"\\n{'‚îÄ' * 50}\")\n",
    "        print(f\"#{i} - OSM ID: {building.get('osm_id', 'N/A')}\")\n",
    "        print(f\"{'‚îÄ' * 50}\")\n",
    "        print(f\"  Risk Score:     {building['risk_score']:.2f}/10 ({building['risk_category']})\")\n",
    "        print(f\"  Soil Score:     {building['soil_score']:.2f}/10\")\n",
    "        print(f\"  Tree Score:     {building['tree_score']:.2f}/10\")\n",
    "        print(f\"  Soil Type:      {building['soil_type']}\")\n",
    "        print(f\"  Building Type:  {building.get('building', 'Unknown')}\")\n",
    "        print(f\"  Nearby Trees:   {building['nearby_trees']}\")\n",
    "        print(f\"  In Root Zone:   {building['trees_in_root_zone']}\")\n",
    "        if building['closest_tree_m']:\n",
    "            print(f\"  Closest Tree:   {building['closest_tree_m']:.1f}m\")\n",
    "        \n",
    "        # Get centroid for reference\n",
    "        centroid = building.geometry.centroid\n",
    "        print(f\"  Location:       ({centroid.y:.6f}, {centroid.x:.6f})\")\n",
    "    \n",
    "    return high_risk\n",
    "\n",
    "# Show high risk buildings analysis\n",
    "if 'scored_buildings' in dir() and not scored_buildings.empty:\n",
    "    high_risk_buildings = analyze_high_risk_buildings(scored_buildings, top_n=10)\n",
    "else:\n",
    "    print(\"Run the scoring cell first to analyze buildings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c2a07d",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# EXPORT RESULTS\n",
    "# ============================================\n",
    "\n",
    "def export_results(scored_buildings, output_prefix='bristol_subsidence'):\n",
    "    \"\"\"\n",
    "    Export scored buildings in multiple formats.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    scored_buildings : GeoDataFrame\n",
    "        Buildings with risk scores\n",
    "    output_prefix : str\n",
    "        Prefix for output filenames\n",
    "    \"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"EXPORTING RESULTS\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # 1. GeoJSON (for web mapping)\n",
    "    geojson_file = f'{output_prefix}_buildings.geojson'\n",
    "    scored_buildings.to_file(geojson_file, driver='GeoJSON')\n",
    "    print(f\"‚úì GeoJSON: {geojson_file}\")\n",
    "    \n",
    "    # 2. Shapefile (for GIS software)\n",
    "    shp_file = f'{output_prefix}_buildings.shp'\n",
    "    # Shapefiles have column name limits, so truncate\n",
    "    export_gdf = scored_buildings.copy()\n",
    "    export_gdf.columns = [c[:10] for c in export_gdf.columns]\n",
    "    export_gdf.to_file(shp_file)\n",
    "    print(f\"‚úì Shapefile: {shp_file}\")\n",
    "    \n",
    "    # 3. CSV summary (for spreadsheets)\n",
    "    csv_file = f'{output_prefix}_summary.csv'\n",
    "    csv_cols = ['osm_id', 'building', 'risk_score', 'risk_category', \n",
    "                'soil_score', 'soil_type', 'tree_score', \n",
    "                'nearby_trees', 'trees_in_root_zone', 'closest_tree_m']\n",
    "    \n",
    "    # Add centroid coordinates\n",
    "    export_df = scored_buildings[csv_cols].copy()\n",
    "    export_df['centroid_lat'] = scored_buildings.geometry.centroid.y\n",
    "    export_df['centroid_lon'] = scored_buildings.geometry.centroid.x\n",
    "    export_df.to_csv(csv_file, index=False)\n",
    "    print(f\"‚úì CSV: {csv_file}\")\n",
    "    \n",
    "    # 4. Summary statistics\n",
    "    stats_file = f'{output_prefix}_statistics.txt'\n",
    "    with open(stats_file, 'w') as f:\n",
    "        f.write(\"SUBSIDENCE RISK ANALYSIS SUMMARY\\n\")\n",
    "        f.write(\"=\" * 50 + \"\\n\\n\")\n",
    "        \n",
    "        f.write(f\"Total Buildings Analyzed: {len(scored_buildings)}\\n\\n\")\n",
    "        \n",
    "        f.write(\"RISK DISTRIBUTION:\\n\")\n",
    "        for cat in ['High', 'Medium', 'Low']:\n",
    "            count = len(scored_buildings[scored_buildings['risk_category'] == cat])\n",
    "            pct = count / len(scored_buildings) * 100\n",
    "            f.write(f\"  {cat}: {count} ({pct:.1f}%)\\n\")\n",
    "        \n",
    "        f.write(\"\\nSCORE STATISTICS:\\n\")\n",
    "        for col in ['risk_score', 'soil_score', 'tree_score']:\n",
    "            f.write(f\"  {col}:\\n\")\n",
    "            f.write(f\"    Mean: {scored_buildings[col].mean():.2f}\\n\")\n",
    "            f.write(f\"    Std:  {scored_buildings[col].std():.2f}\\n\")\n",
    "            f.write(f\"    Min:  {scored_buildings[col].min():.2f}\\n\")\n",
    "            f.write(f\"    Max:  {scored_buildings[col].max():.2f}\\n\")\n",
    "        \n",
    "        f.write(\"\\nSOIL TYPE DISTRIBUTION:\\n\")\n",
    "        for soil, count in scored_buildings['soil_type'].value_counts().items():\n",
    "            pct = count / len(scored_buildings) * 100\n",
    "            f.write(f\"  {soil}: {count} ({pct:.1f}%)\\n\")\n",
    "    \n",
    "    print(f\"‚úì Statistics: {stats_file}\")\n",
    "    \n",
    "    print(f\"\\n{'=' * 60}\")\n",
    "    print(\"EXPORT COMPLETE\")\n",
    "    print(f\"{'=' * 60}\")\n",
    "    \n",
    "    return {\n",
    "        'geojson': geojson_file,\n",
    "        'shapefile': shp_file,\n",
    "        'csv': csv_file,\n",
    "        'statistics': stats_file\n",
    "    }\n",
    "\n",
    "# Export results\n",
    "if 'scored_buildings' in dir() and not scored_buildings.empty:\n",
    "    exported_files = export_results(scored_buildings)\n",
    "else:\n",
    "    print(\"Run the scoring cell first to export results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d893d2c",
   "metadata": {},
   "source": [
    "## 7. Summary\n",
    "\n",
    "This notebook provides a complete workflow for building-level subsidence risk assessment:\n",
    "\n",
    "‚úÖ **Data Collection** - Trees (Bristol API), Buildings (OSM), Soil (BGS WMS with tiled fetching)\n",
    "\n",
    "‚úÖ **Risk Scoring** - Per-building scores combining soil type (40%) + tree proximity (60%)\n",
    "\n",
    "‚úÖ **Spatial Optimization** - R-tree index for fast tree proximity queries (~40x faster)\n",
    "\n",
    "‚úÖ **Visualization** - Interactive map with toggleable layers and legend\n",
    "\n",
    "‚úÖ **Export** - GeoJSON with full risk attributes for each building\n",
    "\n",
    "### Output Files\n",
    "\n",
    "| File | Description |\n",
    "|------|-------------|\n",
    "| `bristol_buildings_scored.geojson` | All buildings with risk scores and attributes |\n",
    "| `subsidence_risk_buildings.html` | Interactive map (open in browser) |\n",
    "\n",
    "### Risk Score Interpretation\n",
    "\n",
    "| Score | Category | Typical Scenario |\n",
    "|-------|----------|------------------|\n",
    "| ‚â• 7.0 | **High** | Clay soil + multiple trees in root zone |\n",
    "| 4.0-7.0 | **Medium** | Some risk factors present |\n",
    "| < 4.0 | **Low** | Sandy/loam soil, few nearby trees |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "subsidence",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
